{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1PZIgcCRT/kG8sHY+B9DH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilberquito/NeuralNetworksCompetition2023/blob/main/Code/ML_STUDENT_COMPETITION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frSDoMZ6nROc",
        "outputId": "2e41768c-89ed-4f1a-842a-d7102161648d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from google.colab import data_table\n",
        "data_table.DataTable.max_columns = 50\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "csv_path = Path('/content/drive/MyDrive/train.csv')\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "-6Meh_vIqdTe",
        "outputId": "ecb278f0-fb78-4ac1-bf9b-861c9cc3cd65"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id      f_00      f_01      f_02      f_03      f_04      f_05  \\\n",
              "0  493553  0.315471 -0.183690  0.664383 -1.186794  0.665098  0.946208   \n",
              "1  237346 -1.286392  1.780592  0.576698 -2.690658  1.321997 -0.675894   \n",
              "2   37368 -0.290303 -0.485907  0.808350 -0.156288  1.083632 -1.129914   \n",
              "3  665220  1.243590  0.035112 -1.013236  0.854267  0.019192  0.597892   \n",
              "4   41499  0.702716  0.817044 -0.064907 -1.045483  0.718374  0.164451   \n",
              "\n",
              "       f_06  f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  \\\n",
              "0  0.729857     0     4     1     3     1     2     4     1     5     2     0   \n",
              "1  0.371070     3     0     3     3     5     3     2     0     1     6     0   \n",
              "2  0.767396     3     1     3     2     3     4     1     1     1     0     2   \n",
              "3 -2.020416     2     0     4     5     0     5     1     0     3     1     1   \n",
              "4 -0.936620     1     2     2     2     2     5     0     3     1     1     2   \n",
              "\n",
              "   f_18      f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n",
              "0     1 -3.690715 -0.628005 -2.832295 -1.409039  3.645067  0.233039 -3.754846   \n",
              "1     1  0.664517 -2.871912  3.826628  3.087653  0.494209  3.210875 -0.666457   \n",
              "2     6 -0.494988 -0.946303  2.333223  2.084169 -4.782668 -1.671375  2.774382   \n",
              "3     3 -3.066427 -2.430158 -0.185332 -0.701691 -2.769142 -6.534231 -0.557677   \n",
              "4     4 -1.899984  1.427460 -4.992610  1.154162 -1.931443  2.325042  2.143811   \n",
              "\n",
              "       f_26        f_27        f_28  f_29  f_30  target  \n",
              "0 -1.061733  BDBBCACIBB   20.308715     1     0       0  \n",
              "1  0.123854  ACBDCBCADA -449.291063     1     0       0  \n",
              "2  2.273130  AABBABCLAF  -86.206118     0     1       1  \n",
              "3 -0.429972  ADBBABEEBA  -30.157403     0     2       1  \n",
              "4 -1.039599  ABBBBBCMBB  296.484562     0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0a67728-18d6-458b-8cc7-4ea4308e80f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_27</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>493553</td>\n",
              "      <td>0.315471</td>\n",
              "      <td>-0.183690</td>\n",
              "      <td>0.664383</td>\n",
              "      <td>-1.186794</td>\n",
              "      <td>0.665098</td>\n",
              "      <td>0.946208</td>\n",
              "      <td>0.729857</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.690715</td>\n",
              "      <td>-0.628005</td>\n",
              "      <td>-2.832295</td>\n",
              "      <td>-1.409039</td>\n",
              "      <td>3.645067</td>\n",
              "      <td>0.233039</td>\n",
              "      <td>-3.754846</td>\n",
              "      <td>-1.061733</td>\n",
              "      <td>BDBBCACIBB</td>\n",
              "      <td>20.308715</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>237346</td>\n",
              "      <td>-1.286392</td>\n",
              "      <td>1.780592</td>\n",
              "      <td>0.576698</td>\n",
              "      <td>-2.690658</td>\n",
              "      <td>1.321997</td>\n",
              "      <td>-0.675894</td>\n",
              "      <td>0.371070</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.664517</td>\n",
              "      <td>-2.871912</td>\n",
              "      <td>3.826628</td>\n",
              "      <td>3.087653</td>\n",
              "      <td>0.494209</td>\n",
              "      <td>3.210875</td>\n",
              "      <td>-0.666457</td>\n",
              "      <td>0.123854</td>\n",
              "      <td>ACBDCBCADA</td>\n",
              "      <td>-449.291063</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37368</td>\n",
              "      <td>-0.290303</td>\n",
              "      <td>-0.485907</td>\n",
              "      <td>0.808350</td>\n",
              "      <td>-0.156288</td>\n",
              "      <td>1.083632</td>\n",
              "      <td>-1.129914</td>\n",
              "      <td>0.767396</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.494988</td>\n",
              "      <td>-0.946303</td>\n",
              "      <td>2.333223</td>\n",
              "      <td>2.084169</td>\n",
              "      <td>-4.782668</td>\n",
              "      <td>-1.671375</td>\n",
              "      <td>2.774382</td>\n",
              "      <td>2.273130</td>\n",
              "      <td>AABBABCLAF</td>\n",
              "      <td>-86.206118</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>665220</td>\n",
              "      <td>1.243590</td>\n",
              "      <td>0.035112</td>\n",
              "      <td>-1.013236</td>\n",
              "      <td>0.854267</td>\n",
              "      <td>0.019192</td>\n",
              "      <td>0.597892</td>\n",
              "      <td>-2.020416</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-3.066427</td>\n",
              "      <td>-2.430158</td>\n",
              "      <td>-0.185332</td>\n",
              "      <td>-0.701691</td>\n",
              "      <td>-2.769142</td>\n",
              "      <td>-6.534231</td>\n",
              "      <td>-0.557677</td>\n",
              "      <td>-0.429972</td>\n",
              "      <td>ADBBABEEBA</td>\n",
              "      <td>-30.157403</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41499</td>\n",
              "      <td>0.702716</td>\n",
              "      <td>0.817044</td>\n",
              "      <td>-0.064907</td>\n",
              "      <td>-1.045483</td>\n",
              "      <td>0.718374</td>\n",
              "      <td>0.164451</td>\n",
              "      <td>-0.936620</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.899984</td>\n",
              "      <td>1.427460</td>\n",
              "      <td>-4.992610</td>\n",
              "      <td>1.154162</td>\n",
              "      <td>-1.931443</td>\n",
              "      <td>2.325042</td>\n",
              "      <td>2.143811</td>\n",
              "      <td>-1.039599</td>\n",
              "      <td>ABBBBBCMBB</td>\n",
              "      <td>296.484562</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0a67728-18d6-458b-8cc7-4ea4308e80f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0a67728-18d6-458b-8cc7-4ea4308e80f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0a67728-18d6-458b-8cc7-4ea4308e80f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 493553,\n            'f': \"493553\",\n        },\n{\n            'v': 0.3154713179849845,\n            'f': \"0.3154713179849845\",\n        },\n{\n            'v': -0.1836904487704342,\n            'f': \"-0.1836904487704342\",\n        },\n{\n            'v': 0.6643825071902617,\n            'f': \"0.6643825071902617\",\n        },\n{\n            'v': -1.1867943779102057,\n            'f': \"-1.1867943779102057\",\n        },\n{\n            'v': 0.6650983554084389,\n            'f': \"0.6650983554084389\",\n        },\n{\n            'v': 0.946207747620988,\n            'f': \"0.946207747620988\",\n        },\n{\n            'v': 0.7298569499431469,\n            'f': \"0.7298569499431469\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': -3.690715300182188,\n            'f': \"-3.690715300182188\",\n        },\n{\n            'v': -0.6280049668119927,\n            'f': \"-0.6280049668119927\",\n        },\n{\n            'v': -2.832295150712397,\n            'f': \"-2.832295150712397\",\n        },\n{\n            'v': -1.4090385458787378,\n            'f': \"-1.4090385458787378\",\n        },\n{\n            'v': 3.645067262233898,\n            'f': \"3.645067262233898\",\n        },\n{\n            'v': 0.2330390733102534,\n            'f': \"0.2330390733102534\",\n        },\n{\n            'v': -3.754846123350904,\n            'f': \"-3.754846123350904\",\n        },\n{\n            'v': -1.0617332126449046,\n            'f': \"-1.0617332126449046\",\n        },\n\"BDBBCACIBB\",\n{\n            'v': 20.30871493564873,\n            'f': \"20.30871493564873\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 237346,\n            'f': \"237346\",\n        },\n{\n            'v': -1.286392342706846,\n            'f': \"-1.286392342706846\",\n        },\n{\n            'v': 1.7805917149101176,\n            'f': \"1.7805917149101176\",\n        },\n{\n            'v': 0.5766976404384039,\n            'f': \"0.5766976404384039\",\n        },\n{\n            'v': -2.690658095318418,\n            'f': \"-2.690658095318418\",\n        },\n{\n            'v': 1.3219967933572998,\n            'f': \"1.3219967933572998\",\n        },\n{\n            'v': -0.6758939824083278,\n            'f': \"-0.6758939824083278\",\n        },\n{\n            'v': 0.3710700267903256,\n            'f': \"0.3710700267903256\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 6,\n            'f': \"6\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0.6645165908993002,\n            'f': \"0.6645165908993002\",\n        },\n{\n            'v': -2.871912315757452,\n            'f': \"-2.871912315757452\",\n        },\n{\n            'v': 3.826627810842657,\n            'f': \"3.826627810842657\",\n        },\n{\n            'v': 3.087653485668633,\n            'f': \"3.087653485668633\",\n        },\n{\n            'v': 0.4942092665117156,\n            'f': \"0.4942092665117156\",\n        },\n{\n            'v': 3.210874753404081,\n            'f': \"3.210874753404081\",\n        },\n{\n            'v': -0.6664566785948545,\n            'f': \"-0.6664566785948545\",\n        },\n{\n            'v': 0.1238538978213764,\n            'f': \"0.1238538978213764\",\n        },\n\"ACBDCBCADA\",\n{\n            'v': -449.29106308063297,\n            'f': \"-449.29106308063297\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 37368,\n            'f': \"37368\",\n        },\n{\n            'v': -0.2903031581594694,\n            'f': \"-0.2903031581594694\",\n        },\n{\n            'v': -0.4859073078779998,\n            'f': \"-0.4859073078779998\",\n        },\n{\n            'v': 0.8083500053822478,\n            'f': \"0.8083500053822478\",\n        },\n{\n            'v': -0.1562882034675039,\n            'f': \"-0.1562882034675039\",\n        },\n{\n            'v': 1.083631744129082,\n            'f': \"1.083631744129082\",\n        },\n{\n            'v': -1.1299142294071929,\n            'f': \"-1.1299142294071929\",\n        },\n{\n            'v': 0.7673957922691375,\n            'f': \"0.7673957922691375\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 6,\n            'f': \"6\",\n        },\n{\n            'v': -0.4949879257256799,\n            'f': \"-0.4949879257256799\",\n        },\n{\n            'v': -0.9463030178123564,\n            'f': \"-0.9463030178123564\",\n        },\n{\n            'v': 2.3332230088140475,\n            'f': \"2.3332230088140475\",\n        },\n{\n            'v': 2.084169468574978,\n            'f': \"2.084169468574978\",\n        },\n{\n            'v': -4.7826682477273135,\n            'f': \"-4.7826682477273135\",\n        },\n{\n            'v': -1.671374690518444,\n            'f': \"-1.671374690518444\",\n        },\n{\n            'v': 2.7743819671532446,\n            'f': \"2.7743819671532446\",\n        },\n{\n            'v': 2.27312974480488,\n            'f': \"2.27312974480488\",\n        },\n\"AABBABCLAF\",\n{\n            'v': -86.20611797456267,\n            'f': \"-86.20611797456267\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 665220,\n            'f': \"665220\",\n        },\n{\n            'v': 1.2435902764135691,\n            'f': \"1.2435902764135691\",\n        },\n{\n            'v': 0.0351124481295802,\n            'f': \"0.0351124481295802\",\n        },\n{\n            'v': -1.0132364049578737,\n            'f': \"-1.0132364049578737\",\n        },\n{\n            'v': 0.854266756747409,\n            'f': \"0.854266756747409\",\n        },\n{\n            'v': 0.0191923478108258,\n            'f': \"0.0191923478108258\",\n        },\n{\n            'v': 0.5978920134148811,\n            'f': \"0.5978920134148811\",\n        },\n{\n            'v': -2.020416084119066,\n            'f': \"-2.020416084119066\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': -3.066426700596244,\n            'f': \"-3.066426700596244\",\n        },\n{\n            'v': -2.430158197671881,\n            'f': \"-2.430158197671881\",\n        },\n{\n            'v': -0.1853322722460298,\n            'f': \"-0.1853322722460298\",\n        },\n{\n            'v': -0.7016912514931994,\n            'f': \"-0.7016912514931994\",\n        },\n{\n            'v': -2.76914243525596,\n            'f': \"-2.76914243525596\",\n        },\n{\n            'v': -6.534230848040475,\n            'f': \"-6.534230848040475\",\n        },\n{\n            'v': -0.5576772758338957,\n            'f': \"-0.5576772758338957\",\n        },\n{\n            'v': -0.4299722583622913,\n            'f': \"-0.4299722583622913\",\n        },\n\"ADBBABEEBA\",\n{\n            'v': -30.15740300923009,\n            'f': \"-30.15740300923009\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 41499,\n            'f': \"41499\",\n        },\n{\n            'v': 0.7027157143556877,\n            'f': \"0.7027157143556877\",\n        },\n{\n            'v': 0.8170440444671354,\n            'f': \"0.8170440444671354\",\n        },\n{\n            'v': -0.064906742184267,\n            'f': \"-0.064906742184267\",\n        },\n{\n            'v': -1.0454825809420276,\n            'f': \"-1.0454825809420276\",\n        },\n{\n            'v': 0.7183736998235606,\n            'f': \"0.7183736998235606\",\n        },\n{\n            'v': 0.1644514962992729,\n            'f': \"0.1644514962992729\",\n        },\n{\n            'v': -0.9366196529132428,\n            'f': \"-0.9366196529132428\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': -1.8999840497433944,\n            'f': \"-1.8999840497433944\",\n        },\n{\n            'v': 1.4274596343623616,\n            'f': \"1.4274596343623616\",\n        },\n{\n            'v': -4.992609842066788,\n            'f': \"-4.992609842066788\",\n        },\n{\n            'v': 1.154162234302733,\n            'f': \"1.154162234302733\",\n        },\n{\n            'v': -1.9314431250014568,\n            'f': \"-1.9314431250014568\",\n        },\n{\n            'v': 2.3250420992192806,\n            'f': \"2.3250420992192806\",\n        },\n{\n            'v': 2.143810732830162,\n            'f': \"2.143810732830162\",\n        },\n{\n            'v': -1.0395985915012504,\n            'f': \"-1.0395985915012504\",\n        },\n\"ABBBBBCMBB\",\n{\n            'v': 296.4845619201336,\n            'f': \"296.4845619201336\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"number\", \"f_00\"], [\"number\", \"f_01\"], [\"number\", \"f_02\"], [\"number\", \"f_03\"], [\"number\", \"f_04\"], [\"number\", \"f_05\"], [\"number\", \"f_06\"], [\"number\", \"f_07\"], [\"number\", \"f_08\"], [\"number\", \"f_09\"], [\"number\", \"f_10\"], [\"number\", \"f_11\"], [\"number\", \"f_12\"], [\"number\", \"f_13\"], [\"number\", \"f_14\"], [\"number\", \"f_15\"], [\"number\", \"f_16\"], [\"number\", \"f_17\"], [\"number\", \"f_18\"], [\"number\", \"f_19\"], [\"number\", \"f_20\"], [\"number\", \"f_21\"], [\"number\", \"f_22\"], [\"number\", \"f_23\"], [\"number\", \"f_24\"], [\"number\", \"f_25\"], [\"number\", \"f_26\"], [\"string\", \"f_27\"], [\"number\", \"f_28\"], [\"number\", \"f_29\"], [\"number\", \"f_30\"], [\"number\", \"target\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.drop(['target', 'f_27', 'id'], axis=1), df['target']\n",
        "X = (X - X.min()) / (X.max() - X.min())\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlPl0dVDrByn",
        "outputId": "f7521bab-1e56-406e-cc68-be2e4b7dd827"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((810000, 30), (810000,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "26pKNWPurBwZ",
        "outputId": "d86646d1-3361-4e42-d119-a949102f62ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                f_00           f_01           f_02           f_03  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.492047       0.493137       0.483409       0.509344   \n",
              "std         0.106824       0.105223       0.104209       0.110100   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.419874       0.421923       0.413105       0.435033   \n",
              "50%         0.492222       0.493239       0.483497       0.509273   \n",
              "75%         0.564173       0.564118       0.553837       0.583519   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_04           f_05           f_06           f_07  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.489579       0.488666       0.500947       0.135472   \n",
              "std         0.103120       0.102858       0.103412       0.110450   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.419932       0.419381       0.431191       0.066667   \n",
              "50%         0.489467       0.488607       0.500879       0.133333   \n",
              "75%         0.559059       0.558114       0.570758       0.200000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_08           f_09           f_10           f_11  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.128624       0.168756       0.155560       0.138772   \n",
              "std         0.099419       0.116962       0.117537       0.118276   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.062500       0.071429       0.071429       0.076923   \n",
              "50%         0.125000       0.142857       0.142857       0.153846   \n",
              "75%         0.187500       0.214286       0.214286       0.230769   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_12           f_13           f_14           f_15  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.177645       0.186609       0.108244       0.150097   \n",
              "std         0.110167       0.128143       0.097128       0.112068   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.125000       0.083333       0.000000       0.071429   \n",
              "50%         0.187500       0.166667       0.071429       0.142857   \n",
              "75%         0.250000       0.250000       0.142857       0.214286   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_16           f_17           f_18           f_19  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.139767       0.154813       0.158921       0.517581   \n",
              "std         0.103999       0.122292       0.120430       0.103392   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.066667       0.083333       0.076923       0.448633   \n",
              "50%         0.133333       0.166667       0.153846       0.518558   \n",
              "75%         0.200000       0.250000       0.230769       0.587767   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_20           f_21           f_22           f_23  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.487353       0.496712       0.510560       0.486064   \n",
              "std         0.105602       0.102610       0.105636       0.099971   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.415828       0.428052       0.440037       0.418822   \n",
              "50%         0.486864       0.496870       0.512280       0.485208   \n",
              "75%         0.558750       0.565416       0.582559       0.552316   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_24           f_25           f_26           f_28  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.465154       0.494703       0.538599       0.499857   \n",
              "std         0.100273       0.098855       0.091013       0.097074   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.397385       0.428586       0.479097       0.435201   \n",
              "50%         0.465171       0.494076       0.540384       0.499806   \n",
              "75%         0.532749       0.560920       0.600025       0.564667   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                f_29           f_30  \n",
              "count  810000.000000  810000.000000  \n",
              "mean        0.345565       0.501186  \n",
              "std         0.475553       0.409425  \n",
              "min         0.000000       0.000000  \n",
              "25%         0.000000       0.000000  \n",
              "50%         0.000000       0.500000  \n",
              "75%         1.000000       1.000000  \n",
              "max         1.000000       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cc33f11-ae3b-40c1-a756-c813f7413017\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.492047</td>\n",
              "      <td>0.493137</td>\n",
              "      <td>0.483409</td>\n",
              "      <td>0.509344</td>\n",
              "      <td>0.489579</td>\n",
              "      <td>0.488666</td>\n",
              "      <td>0.500947</td>\n",
              "      <td>0.135472</td>\n",
              "      <td>0.128624</td>\n",
              "      <td>0.168756</td>\n",
              "      <td>0.155560</td>\n",
              "      <td>0.138772</td>\n",
              "      <td>0.177645</td>\n",
              "      <td>0.186609</td>\n",
              "      <td>0.108244</td>\n",
              "      <td>0.150097</td>\n",
              "      <td>0.139767</td>\n",
              "      <td>0.154813</td>\n",
              "      <td>0.158921</td>\n",
              "      <td>0.517581</td>\n",
              "      <td>0.487353</td>\n",
              "      <td>0.496712</td>\n",
              "      <td>0.510560</td>\n",
              "      <td>0.486064</td>\n",
              "      <td>0.465154</td>\n",
              "      <td>0.494703</td>\n",
              "      <td>0.538599</td>\n",
              "      <td>0.499857</td>\n",
              "      <td>0.345565</td>\n",
              "      <td>0.501186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.106824</td>\n",
              "      <td>0.105223</td>\n",
              "      <td>0.104209</td>\n",
              "      <td>0.110100</td>\n",
              "      <td>0.103120</td>\n",
              "      <td>0.102858</td>\n",
              "      <td>0.103412</td>\n",
              "      <td>0.110450</td>\n",
              "      <td>0.099419</td>\n",
              "      <td>0.116962</td>\n",
              "      <td>0.117537</td>\n",
              "      <td>0.118276</td>\n",
              "      <td>0.110167</td>\n",
              "      <td>0.128143</td>\n",
              "      <td>0.097128</td>\n",
              "      <td>0.112068</td>\n",
              "      <td>0.103999</td>\n",
              "      <td>0.122292</td>\n",
              "      <td>0.120430</td>\n",
              "      <td>0.103392</td>\n",
              "      <td>0.105602</td>\n",
              "      <td>0.102610</td>\n",
              "      <td>0.105636</td>\n",
              "      <td>0.099971</td>\n",
              "      <td>0.100273</td>\n",
              "      <td>0.098855</td>\n",
              "      <td>0.091013</td>\n",
              "      <td>0.097074</td>\n",
              "      <td>0.475553</td>\n",
              "      <td>0.409425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.419874</td>\n",
              "      <td>0.421923</td>\n",
              "      <td>0.413105</td>\n",
              "      <td>0.435033</td>\n",
              "      <td>0.419932</td>\n",
              "      <td>0.419381</td>\n",
              "      <td>0.431191</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.448633</td>\n",
              "      <td>0.415828</td>\n",
              "      <td>0.428052</td>\n",
              "      <td>0.440037</td>\n",
              "      <td>0.418822</td>\n",
              "      <td>0.397385</td>\n",
              "      <td>0.428586</td>\n",
              "      <td>0.479097</td>\n",
              "      <td>0.435201</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.492222</td>\n",
              "      <td>0.493239</td>\n",
              "      <td>0.483497</td>\n",
              "      <td>0.509273</td>\n",
              "      <td>0.489467</td>\n",
              "      <td>0.488607</td>\n",
              "      <td>0.500879</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.518558</td>\n",
              "      <td>0.486864</td>\n",
              "      <td>0.496870</td>\n",
              "      <td>0.512280</td>\n",
              "      <td>0.485208</td>\n",
              "      <td>0.465171</td>\n",
              "      <td>0.494076</td>\n",
              "      <td>0.540384</td>\n",
              "      <td>0.499806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.564173</td>\n",
              "      <td>0.564118</td>\n",
              "      <td>0.553837</td>\n",
              "      <td>0.583519</td>\n",
              "      <td>0.559059</td>\n",
              "      <td>0.558114</td>\n",
              "      <td>0.570758</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.587767</td>\n",
              "      <td>0.558750</td>\n",
              "      <td>0.565416</td>\n",
              "      <td>0.582559</td>\n",
              "      <td>0.552316</td>\n",
              "      <td>0.532749</td>\n",
              "      <td>0.560920</td>\n",
              "      <td>0.600025</td>\n",
              "      <td>0.564667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cc33f11-ae3b-40c1-a756-c813f7413017')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cc33f11-ae3b-40c1-a756-c813f7413017 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cc33f11-ae3b-40c1-a756-c813f7413017');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[\"count\",\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        },\n{\n            'v': 810000.0,\n            'f': \"810000.0\",\n        }],\n [\"mean\",\n{\n            'v': 0.4920469556017546,\n            'f': \"0.4920469556017546\",\n        },\n{\n            'v': 0.4931367257883375,\n            'f': \"0.4931367257883375\",\n        },\n{\n            'v': 0.4834093802087977,\n            'f': \"0.4834093802087977\",\n        },\n{\n            'v': 0.5093435835879793,\n            'f': \"0.5093435835879793\",\n        },\n{\n            'v': 0.48957858936674864,\n            'f': \"0.48957858936674864\",\n        },\n{\n            'v': 0.48866604703332867,\n            'f': \"0.48866604703332867\",\n        },\n{\n            'v': 0.5009471454629172,\n            'f': \"0.5009471454629172\",\n        },\n{\n            'v': 0.1354724279835391,\n            'f': \"0.1354724279835391\",\n        },\n{\n            'v': 0.12862376543209877,\n            'f': \"0.12862376543209877\",\n        },\n{\n            'v': 0.1687564373897707,\n            'f': \"0.1687564373897707\",\n        },\n{\n            'v': 0.1555604938271605,\n            'f': \"0.1555604938271605\",\n        },\n{\n            'v': 0.13877217473884138,\n            'f': \"0.13877217473884138\",\n        },\n{\n            'v': 0.1776451388888889,\n            'f': \"0.1776451388888889\",\n        },\n{\n            'v': 0.18660895061728394,\n            'f': \"0.18660895061728394\",\n        },\n{\n            'v': 0.1082436507936508,\n            'f': \"0.1082436507936508\",\n        },\n{\n            'v': 0.1500970899470899,\n            'f': \"0.1500970899470899\",\n        },\n{\n            'v': 0.1397668312757202,\n            'f': \"0.1397668312757202\",\n        },\n{\n            'v': 0.15481316872427986,\n            'f': \"0.15481316872427986\",\n        },\n{\n            'v': 0.15892117758784427,\n            'f': \"0.15892117758784427\",\n        },\n{\n            'v': 0.5175807077175668,\n            'f': \"0.5175807077175668\",\n        },\n{\n            'v': 0.48735332931379455,\n            'f': \"0.48735332931379455\",\n        },\n{\n            'v': 0.4967123091230569,\n            'f': \"0.4967123091230569\",\n        },\n{\n            'v': 0.5105603922517863,\n            'f': \"0.5105603922517863\",\n        },\n{\n            'v': 0.4860635275909901,\n            'f': \"0.4860635275909901\",\n        },\n{\n            'v': 0.4651544004300661,\n            'f': \"0.4651544004300661\",\n        },\n{\n            'v': 0.4947027530696266,\n            'f': \"0.4947027530696266\",\n        },\n{\n            'v': 0.538598594370526,\n            'f': \"0.538598594370526\",\n        },\n{\n            'v': 0.49985652583879764,\n            'f': \"0.49985652583879764\",\n        },\n{\n            'v': 0.34556543209876545,\n            'f': \"0.34556543209876545\",\n        },\n{\n            'v': 0.5011864197530864,\n            'f': \"0.5011864197530864\",\n        }],\n [\"std\",\n{\n            'v': 0.1068244926901292,\n            'f': \"0.1068244926901292\",\n        },\n{\n            'v': 0.1052234675238886,\n            'f': \"0.1052234675238886\",\n        },\n{\n            'v': 0.10420900836024782,\n            'f': \"0.10420900836024782\",\n        },\n{\n            'v': 0.11009977954418984,\n            'f': \"0.11009977954418984\",\n        },\n{\n            'v': 0.10311951234973336,\n            'f': \"0.10311951234973336\",\n        },\n{\n            'v': 0.102858381708609,\n            'f': \"0.102858381708609\",\n        },\n{\n            'v': 0.10341177465389745,\n            'f': \"0.10341177465389745\",\n        },\n{\n            'v': 0.1104499543740449,\n            'f': \"0.1104499543740449\",\n        },\n{\n            'v': 0.09941863089289042,\n            'f': \"0.09941863089289042\",\n        },\n{\n            'v': 0.11696233690469292,\n            'f': \"0.11696233690469292\",\n        },\n{\n            'v': 0.11753710469375551,\n            'f': \"0.11753710469375551\",\n        },\n{\n            'v': 0.11827610191652406,\n            'f': \"0.11827610191652406\",\n        },\n{\n            'v': 0.11016698838763303,\n            'f': \"0.11016698838763303\",\n        },\n{\n            'v': 0.12814267061771797,\n            'f': \"0.12814267061771797\",\n        },\n{\n            'v': 0.09712844431385655,\n            'f': \"0.09712844431385655\",\n        },\n{\n            'v': 0.1120679819760513,\n            'f': \"0.1120679819760513\",\n        },\n{\n            'v': 0.10399852602696333,\n            'f': \"0.10399852602696333\",\n        },\n{\n            'v': 0.12229226395666443,\n            'f': \"0.12229226395666443\",\n        },\n{\n            'v': 0.12043025390604199,\n            'f': \"0.12043025390604199\",\n        },\n{\n            'v': 0.10339222458483809,\n            'f': \"0.10339222458483809\",\n        },\n{\n            'v': 0.10560182076946305,\n            'f': \"0.10560182076946305\",\n        },\n{\n            'v': 0.1026095196873899,\n            'f': \"0.1026095196873899\",\n        },\n{\n            'v': 0.10563563105535384,\n            'f': \"0.10563563105535384\",\n        },\n{\n            'v': 0.0999712254889244,\n            'f': \"0.0999712254889244\",\n        },\n{\n            'v': 0.10027297835639704,\n            'f': \"0.10027297835639704\",\n        },\n{\n            'v': 0.09885485313076717,\n            'f': \"0.09885485313076717\",\n        },\n{\n            'v': 0.09101298014200426,\n            'f': \"0.09101298014200426\",\n        },\n{\n            'v': 0.09707409233915582,\n            'f': \"0.09707409233915582\",\n        },\n{\n            'v': 0.4755525664266678,\n            'f': \"0.4755525664266678\",\n        },\n{\n            'v': 0.40942526335240914,\n            'f': \"0.40942526335240914\",\n        }],\n [\"min\",\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        }],\n [\"25%\",\n{\n            'v': 0.4198741993742609,\n            'f': \"0.4198741993742609\",\n        },\n{\n            'v': 0.42192329062060996,\n            'f': \"0.42192329062060996\",\n        },\n{\n            'v': 0.41310460625697654,\n            'f': \"0.41310460625697654\",\n        },\n{\n            'v': 0.4350334658304539,\n            'f': \"0.4350334658304539\",\n        },\n{\n            'v': 0.4199324863892951,\n            'f': \"0.4199324863892951\",\n        },\n{\n            'v': 0.419380886012073,\n            'f': \"0.419380886012073\",\n        },\n{\n            'v': 0.43119103662685376,\n            'f': \"0.43119103662685376\",\n        },\n{\n            'v': 0.06666666666666667,\n            'f': \"0.06666666666666667\",\n        },\n{\n            'v': 0.0625,\n            'f': \"0.0625\",\n        },\n{\n            'v': 0.07142857142857142,\n            'f': \"0.07142857142857142\",\n        },\n{\n            'v': 0.07142857142857142,\n            'f': \"0.07142857142857142\",\n        },\n{\n            'v': 0.07692307692307693,\n            'f': \"0.07692307692307693\",\n        },\n{\n            'v': 0.125,\n            'f': \"0.125\",\n        },\n{\n            'v': 0.08333333333333333,\n            'f': \"0.08333333333333333\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.07142857142857142,\n            'f': \"0.07142857142857142\",\n        },\n{\n            'v': 0.06666666666666667,\n            'f': \"0.06666666666666667\",\n        },\n{\n            'v': 0.08333333333333333,\n            'f': \"0.08333333333333333\",\n        },\n{\n            'v': 0.07692307692307693,\n            'f': \"0.07692307692307693\",\n        },\n{\n            'v': 0.44863262116023145,\n            'f': \"0.44863262116023145\",\n        },\n{\n            'v': 0.4158278079206496,\n            'f': \"0.4158278079206496\",\n        },\n{\n            'v': 0.4280517038769761,\n            'f': \"0.4280517038769761\",\n        },\n{\n            'v': 0.4400374956839308,\n            'f': \"0.4400374956839308\",\n        },\n{\n            'v': 0.4188224205080938,\n            'f': \"0.4188224205080938\",\n        },\n{\n            'v': 0.39738532576108054,\n            'f': \"0.39738532576108054\",\n        },\n{\n            'v': 0.4285861102006323,\n            'f': \"0.4285861102006323\",\n        },\n{\n            'v': 0.4790970081470492,\n            'f': \"0.4790970081470492\",\n        },\n{\n            'v': 0.435201086248169,\n            'f': \"0.435201086248169\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        }],\n [\"50%\",\n{\n            'v': 0.49222209228757696,\n            'f': \"0.49222209228757696\",\n        },\n{\n            'v': 0.49323863458478107,\n            'f': \"0.49323863458478107\",\n        },\n{\n            'v': 0.48349707330466296,\n            'f': \"0.48349707330466296\",\n        },\n{\n            'v': 0.5092725514399326,\n            'f': \"0.5092725514399326\",\n        },\n{\n            'v': 0.48946651397847574,\n            'f': \"0.48946651397847574\",\n        },\n{\n            'v': 0.48860719511165296,\n            'f': \"0.48860719511165296\",\n        },\n{\n            'v': 0.5008789086491003,\n            'f': \"0.5008789086491003\",\n        },\n{\n            'v': 0.13333333333333333,\n            'f': \"0.13333333333333333\",\n        },\n{\n            'v': 0.125,\n            'f': \"0.125\",\n        },\n{\n            'v': 0.14285714285714285,\n            'f': \"0.14285714285714285\",\n        },\n{\n            'v': 0.14285714285714285,\n            'f': \"0.14285714285714285\",\n        },\n{\n            'v': 0.15384615384615385,\n            'f': \"0.15384615384615385\",\n        },\n{\n            'v': 0.1875,\n            'f': \"0.1875\",\n        },\n{\n            'v': 0.16666666666666666,\n            'f': \"0.16666666666666666\",\n        },\n{\n            'v': 0.07142857142857142,\n            'f': \"0.07142857142857142\",\n        },\n{\n            'v': 0.14285714285714285,\n            'f': \"0.14285714285714285\",\n        },\n{\n            'v': 0.13333333333333333,\n            'f': \"0.13333333333333333\",\n        },\n{\n            'v': 0.16666666666666666,\n            'f': \"0.16666666666666666\",\n        },\n{\n            'v': 0.15384615384615385,\n            'f': \"0.15384615384615385\",\n        },\n{\n            'v': 0.5185581039946123,\n            'f': \"0.5185581039946123\",\n        },\n{\n            'v': 0.48686404041636216,\n            'f': \"0.48686404041636216\",\n        },\n{\n            'v': 0.49687015600941264,\n            'f': \"0.49687015600941264\",\n        },\n{\n            'v': 0.5122802621314271,\n            'f': \"0.5122802621314271\",\n        },\n{\n            'v': 0.48520780727897506,\n            'f': \"0.48520780727897506\",\n        },\n{\n            'v': 0.4651708837592655,\n            'f': \"0.4651708837592655\",\n        },\n{\n            'v': 0.4940764765723727,\n            'f': \"0.4940764765723727\",\n        },\n{\n            'v': 0.5403835861704589,\n            'f': \"0.5403835861704589\",\n        },\n{\n            'v': 0.49980559023593063,\n            'f': \"0.49980559023593063\",\n        },\n{\n            'v': 0.0,\n            'f': \"0.0\",\n        },\n{\n            'v': 0.5,\n            'f': \"0.5\",\n        }],\n [\"75%\",\n{\n            'v': 0.5641728054021995,\n            'f': \"0.5641728054021995\",\n        },\n{\n            'v': 0.5641180211760901,\n            'f': \"0.5641180211760901\",\n        },\n{\n            'v': 0.553836684122659,\n            'f': \"0.553836684122659\",\n        },\n{\n            'v': 0.5835186017883011,\n            'f': \"0.5835186017883011\",\n        },\n{\n            'v': 0.5590593110675474,\n            'f': \"0.5590593110675474\",\n        },\n{\n            'v': 0.5581143146310639,\n            'f': \"0.5581143146310639\",\n        },\n{\n            'v': 0.5707578103296014,\n            'f': \"0.5707578103296014\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n{\n            'v': 0.1875,\n            'f': \"0.1875\",\n        },\n{\n            'v': 0.21428571428571427,\n            'f': \"0.21428571428571427\",\n        },\n{\n            'v': 0.21428571428571427,\n            'f': \"0.21428571428571427\",\n        },\n{\n            'v': 0.23076923076923078,\n            'f': \"0.23076923076923078\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.14285714285714285,\n            'f': \"0.14285714285714285\",\n        },\n{\n            'v': 0.21428571428571427,\n            'f': \"0.21428571428571427\",\n        },\n{\n            'v': 0.2,\n            'f': \"0.2\",\n        },\n{\n            'v': 0.25,\n            'f': \"0.25\",\n        },\n{\n            'v': 0.23076923076923078,\n            'f': \"0.23076923076923078\",\n        },\n{\n            'v': 0.5877667217494736,\n            'f': \"0.5877667217494736\",\n        },\n{\n            'v': 0.5587495118333151,\n            'f': \"0.5587495118333151\",\n        },\n{\n            'v': 0.5654164234331276,\n            'f': \"0.5654164234331276\",\n        },\n{\n            'v': 0.5825593339308599,\n            'f': \"0.5825593339308599\",\n        },\n{\n            'v': 0.5523160812315038,\n            'f': \"0.5523160812315038\",\n        },\n{\n            'v': 0.5327489549490094,\n            'f': \"0.5327489549490094\",\n        },\n{\n            'v': 0.5609200957385414,\n            'f': \"0.5609200957385414\",\n        },\n{\n            'v': 0.6000245735589274,\n            'f': \"0.6000245735589274\",\n        },\n{\n            'v': 0.5646672576722627,\n            'f': \"0.5646672576722627\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        }],\n [\"max\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        }]],\n        columns: [[\"string\", \"index\"], [\"number\", \"f_00\"], [\"number\", \"f_01\"], [\"number\", \"f_02\"], [\"number\", \"f_03\"], [\"number\", \"f_04\"], [\"number\", \"f_05\"], [\"number\", \"f_06\"], [\"number\", \"f_07\"], [\"number\", \"f_08\"], [\"number\", \"f_09\"], [\"number\", \"f_10\"], [\"number\", \"f_11\"], [\"number\", \"f_12\"], [\"number\", \"f_13\"], [\"number\", \"f_14\"], [\"number\", \"f_15\"], [\"number\", \"f_16\"], [\"number\", \"f_17\"], [\"number\", \"f_18\"], [\"number\", \"f_19\"], [\"number\", \"f_20\"], [\"number\", \"f_21\"], [\"number\", \"f_22\"], [\"number\", \"f_23\"], [\"number\", \"f_24\"], [\"number\", \"f_25\"], [\"number\", \"f_26\"], [\"number\", \"f_28\"], [\"number\", \"f_29\"], [\"number\", \"f_30\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmznjs5grBnV",
        "outputId": "c7388ce9-7b1c-4dfc-c48a-4b832222cc6b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415945\n",
              "1    394055\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X), type(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nc_P-uEg4BZ",
        "outputId": "da2894c5-9823-461f-ec2f-33f130e7e10b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame, pandas.core.series.Series)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryClassifierNet(nn.Module):\n",
        "\n",
        "  def __init__(self, input_features=30):\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=64, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=64, out_features=128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=128, out_features=128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=128, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=64, out_features=32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=32, out_features=1),\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.main(x)"
      ],
      "metadata": {
        "id": "6xuWymPQrBd_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "\n",
        "\n",
        "# Define a custom dataset by extending the PyTorch Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, labels, transform=None):\n",
        "    self.data = data\n",
        "    self.labels = labels \n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    item = self.data[index]\n",
        "    label = self.labels[index]\n",
        "    if self.transform:\n",
        "      item = self.transform(item)\n",
        "    return item, label\n"
      ],
      "metadata": {
        "id": "EYmg7g-wTWJO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare the hole dataset\n",
        "X_tensor, y_tensor = torch.from_numpy(X.to_numpy()), torch.from_numpy(y.to_numpy())\n",
        "X_tensor, y_tensor = X_tensor.type(torch.float), y_tensor.type(torch.float)\n",
        "dataset = CustomDataset(data=X_tensor, labels=y_tensor)"
      ],
      "metadata": {
        "id": "ceGWFcgVykIZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare the train and test dataset\n",
        "import numpy as np\n",
        "\n",
        "test_size = 0.2\n",
        "train_size = 1 - test_size\n",
        "\n",
        "# Stratify by label\n",
        "labels = np.array(y)\n",
        "positive_indices = np.where(labels == 1)[0]\n",
        "negative_indices = np.where(labels == 0)[0]\n",
        "\n",
        "positive_split = int(train_size * len(positive_indices))\n",
        "negative_split = int(train_size * len(negative_indices))\n",
        "\n",
        "positive_train_indices = positive_indices[:positive_split]\n",
        "positive_test_indices = positive_indices[positive_split:]\n",
        "negative_train_indices = negative_indices[:negative_split]\n",
        "negative_test_indices = negative_indices[negative_split:]\n",
        "\n",
        "train_indices = np.concatenate([positive_train_indices, negative_train_indices])\n",
        "test_indices = np.concatenate([positive_test_indices, negative_test_indices])\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
      ],
      "metadata": {
        "id": "5LkKFcbPwlHM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate\n",
        "def validation(model, device, valid_loader, criteria):\n",
        "  # Settings\n",
        "  model.eval()\n",
        "  loss_total = 0\n",
        "  accuracy_total = 0\n",
        "\n",
        "  # Test validation data\n",
        "  with torch.inference_mode():\n",
        "    for inputs, labels in valid_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      outputs = model(inputs).squeeze(dim=1)\n",
        "      loss = criteria(outputs, labels)\n",
        "      loss_total += loss.item()\n",
        "      accuracy_total += torch.sum(torch.round(torch.sigmoid(outputs)) == labels)\n",
        "\n",
        "  return (loss_total / len(valid_loader), accuracy_total / len(valid_loader))\n",
        "\n",
        "# Train\n",
        "def train(device, model, epochs, optimizer, criteria, train_loader, valid_loader):\n",
        "    # Early stopping\n",
        "    last_loss = 100\n",
        "    patience = 2\n",
        "    trigger_times = 0\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "\n",
        "        for times, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward and backward propagation\n",
        "            outputs = model(inputs).squeeze(dim=1)\n",
        "            loss = criteria(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        # Train loss and train accuracy\n",
        "        train_current_loss, train_current_accuracy = validation(model, device, train_loader, criteria)\n",
        "\n",
        "        # Early stopping\n",
        "        current_loss, current_accuracy = validation(model, device, valid_loader, criteria)\n",
        "        print('[{}/{} | Train loss: {:.8} | Train accuracy: {:.8} | Test loss: {:.8} | Test accuracy: {:.8}]'.format(epoch, epochs, train_current_loss, train_current_accuracy, current_loss, current_accuracy))\n",
        "\n",
        "        if current_loss > last_loss:\n",
        "            trigger_times += 1\n",
        "            print('trigger times:', trigger_times)\n",
        "\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!\\nStart to test process.')\n",
        "                return model\n",
        "\n",
        "        else:\n",
        "            print('trigger times: 0')\n",
        "            trigger_times = 0\n",
        "\n",
        "        last_loss = current_loss\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KUnpQLqcwylO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = BinaryClassifierNet(input_features=30)\n",
        "epochs = 100\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
        "criteria = nn.BCEWithLogitsLoss()\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = train(device, model, epochs, optimizer, criteria, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "sZnDhkhlwyiV",
        "outputId": "d5c2646c-1dff-41af-f336-44eda69a44f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/100 | Train loss: 0.69278496 | Train accuracy: 32.864792 | Test loss: 0.69278603 | Test accuracy: 32.855057]\n",
            "trigger times: 0\n",
            "[2/100 | Train loss: 0.69277092 | Train accuracy: 32.864792 | Test loss: 0.69277016 | Test accuracy: 32.855057]\n",
            "trigger times: 0\n",
            "[3/100 | Train loss: 0.69277913 | Train accuracy: 32.864792 | Test loss: 0.69277947 | Test accuracy: 32.855057]\n",
            "trigger times: 1\n",
            "[4/100 | Train loss: 0.69274139 | Train accuracy: 32.864792 | Test loss: 0.69273937 | Test accuracy: 32.855057]\n",
            "trigger times: 0\n",
            "[5/100 | Train loss: 0.69264556 | Train accuracy: 32.864792 | Test loss: 0.69264525 | Test accuracy: 32.855057]\n",
            "trigger times: 0\n",
            "[6/100 | Train loss: 0.69125171 | Train accuracy: 32.864792 | Test loss: 0.69125387 | Test accuracy: 32.855057]\n",
            "trigger times: 0\n",
            "[7/100 | Train loss: 0.57881604 | Train accuracy: 44.719604 | Test loss: 0.57941492 | Test accuracy: 44.658375]\n",
            "trigger times: 0\n",
            "[8/100 | Train loss: 0.54621653 | Train accuracy: 46.462322 | Test loss: 0.54618877 | Test accuracy: 46.522514]\n",
            "trigger times: 0\n",
            "[9/100 | Train loss: 0.49175449 | Train accuracy: 49.160694 | Test loss: 0.4925227 | Test accuracy: 49.148499]\n",
            "trigger times: 0\n",
            "[10/100 | Train loss: 0.4662586 | Train accuracy: 50.265976 | Test loss: 0.46740977 | Test accuracy: 50.280807]\n",
            "trigger times: 0\n",
            "[11/100 | Train loss: 0.46424071 | Train accuracy: 50.253532 | Test loss: 0.46685234 | Test accuracy: 50.14613]\n",
            "trigger times: 0\n",
            "[12/100 | Train loss: 0.43293596 | Train accuracy: 51.641186 | Test loss: 0.43429195 | Test accuracy: 51.578201]\n",
            "trigger times: 0\n",
            "[13/100 | Train loss: 0.43846419 | Train accuracy: 51.505878 | Test loss: 0.4396096 | Test accuracy: 51.505135]\n",
            "trigger times: 1\n",
            "[14/100 | Train loss: 0.40585461 | Train accuracy: 52.692348 | Test loss: 0.40816604 | Test accuracy: 52.635071]\n",
            "trigger times: 0\n",
            "[15/100 | Train loss: 0.38662572 | Train accuracy: 53.495605 | Test loss: 0.38994736 | Test accuracy: 53.353477]\n",
            "trigger times: 0\n",
            "[16/100 | Train loss: 0.38117675 | Train accuracy: 53.609779 | Test loss: 0.38478169 | Test accuracy: 53.480255]\n",
            "trigger times: 0\n",
            "[17/100 | Train loss: 0.37602616 | Train accuracy: 53.753284 | Test loss: 0.37862038 | Test accuracy: 53.665482]\n",
            "trigger times: 0\n",
            "[18/100 | Train loss: 0.37448206 | Train accuracy: 53.883953 | Test loss: 0.37755979 | Test accuracy: 53.79858]\n",
            "trigger times: 0\n",
            "[19/100 | Train loss: 0.34986907 | Train accuracy: 54.722965 | Test loss: 0.35399862 | Test accuracy: 54.597946]\n",
            "trigger times: 0\n",
            "[20/100 | Train loss: 0.3608271 | Train accuracy: 54.326225 | Test loss: 0.36476003 | Test accuracy: 54.176937]\n",
            "trigger times: 1\n",
            "[21/100 | Train loss: 0.353946 | Train accuracy: 54.666668 | Test loss: 0.35605155 | Test accuracy: 54.618877]\n",
            "trigger times: 0\n",
            "[22/100 | Train loss: 0.32915352 | Train accuracy: 55.575706 | Test loss: 0.33280246 | Test accuracy: 55.447868]\n",
            "trigger times: 0\n",
            "[23/100 | Train loss: 0.32839678 | Train accuracy: 55.580051 | Test loss: 0.33176677 | Test accuracy: 55.434441]\n",
            "trigger times: 0\n",
            "[24/100 | Train loss: 0.32581507 | Train accuracy: 55.641781 | Test loss: 0.329076 | Test accuracy: 55.478672]\n",
            "trigger times: 0\n",
            "[25/100 | Train loss: 0.33234341 | Train accuracy: 55.382717 | Test loss: 0.33632656 | Test accuracy: 55.225513]\n",
            "trigger times: 1\n",
            "[26/100 | Train loss: 0.32728212 | Train accuracy: 55.58667 | Test loss: 0.33153122 | Test accuracy: 55.45932]\n",
            "trigger times: 0\n",
            "[27/100 | Train loss: 0.32155541 | Train accuracy: 55.771358 | Test loss: 0.32534408 | Test accuracy: 55.670223]\n",
            "trigger times: 0\n",
            "[28/100 | Train loss: 0.30854607 | Train accuracy: 56.295509 | Test loss: 0.31282578 | Test accuracy: 56.125591]\n",
            "trigger times: 0\n",
            "[29/100 | Train loss: 0.31647757 | Train accuracy: 55.974125 | Test loss: 0.32088786 | Test accuracy: 55.806477]\n",
            "trigger times: 1\n",
            "[30/100 | Train loss: 0.30563248 | Train accuracy: 56.424988 | Test loss: 0.31054539 | Test accuracy: 56.210506]\n",
            "trigger times: 0\n",
            "[31/100 | Train loss: 0.30521789 | Train accuracy: 56.37373 | Test loss: 0.31013462 | Test accuracy: 56.21722]\n",
            "trigger times: 0\n",
            "[32/100 | Train loss: 0.3010709 | Train accuracy: 56.479805 | Test loss: 0.30672044 | Test accuracy: 56.295418]\n",
            "trigger times: 0\n",
            "[33/100 | Train loss: 0.30818832 | Train accuracy: 56.230026 | Test loss: 0.31415983 | Test accuracy: 56.036335]\n",
            "trigger times: 1\n",
            "[34/100 | Train loss: 0.29605965 | Train accuracy: 56.713978 | Test loss: 0.30219382 | Test accuracy: 56.510666]\n",
            "trigger times: 0\n",
            "[35/100 | Train loss: 0.29990704 | Train accuracy: 56.571854 | Test loss: 0.30576446 | Test accuracy: 56.349525]\n",
            "trigger times: 1\n",
            "[36/100 | Train loss: 0.293056 | Train accuracy: 56.803459 | Test loss: 0.29981282 | Test accuracy: 56.584915]\n",
            "trigger times: 0\n",
            "[37/100 | Train loss: 0.31095808 | Train accuracy: 56.212151 | Test loss: 0.31734628 | Test accuracy: 56.032387]\n",
            "trigger times: 1\n",
            "[38/100 | Train loss: 0.30761196 | Train accuracy: 56.286224 | Test loss: 0.31467995 | Test accuracy: 56.069115]\n",
            "trigger times: 0\n",
            "[39/100 | Train loss: 0.28851711 | Train accuracy: 56.939064 | Test loss: 0.29536995 | Test accuracy: 56.728672]\n",
            "trigger times: 0\n",
            "[40/100 | Train loss: 0.2934991 | Train accuracy: 56.798519 | Test loss: 0.29982872 | Test accuracy: 56.587677]\n",
            "trigger times: 1\n",
            "[41/100 | Train loss: 0.28594254 | Train accuracy: 57.080299 | Test loss: 0.29268585 | Test accuracy: 56.897316]\n",
            "trigger times: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-153a5237b505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-672464f362be>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device, model, epochs, optimizer, criteria, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iekQga58wybC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j44nOD2HwyYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QqrCvTnwyT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fDII01Oiwx6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}