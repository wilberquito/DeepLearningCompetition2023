{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilberquito/NeuralNetworksCompetition2023/blob/main/Code/ML_STUDENT_COMPETITION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54WRH8cPepW"
      },
      "source": [
        "# M.L Competition Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vH9vPZFyPepb"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frSDoMZ6nROc",
        "outputId": "c263d22d-2e5d-466a-b218-135c63e9c30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    from google.colab import data_table\n",
        "    data_table.DataTable.max_columns = 50\n",
        "    data_table.enable_dataframe_formatter()\n",
        "else:\n",
        "    from IPython.core.interactiveshell import InteractiveShell\n",
        "    InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-6Meh_vIqdTe"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "q-5llJpgPepf",
        "outputId": "95985937-778d-4483-abc8-474df4a660d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "yKXMcANfPepf",
        "outputId": "822d4e14-40ea-4629-c387-b7a8bf269379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id      f_00      f_01      f_02      f_03      f_04      f_05  \\\n",
              "0  493553  0.315471 -0.183690  0.664383 -1.186794  0.665098  0.946208   \n",
              "1  237346 -1.286392  1.780592  0.576698 -2.690658  1.321997 -0.675894   \n",
              "2   37368 -0.290303 -0.485907  0.808350 -0.156288  1.083632 -1.129914   \n",
              "3  665220  1.243590  0.035112 -1.013236  0.854267  0.019192  0.597892   \n",
              "4   41499  0.702716  0.817044 -0.064907 -1.045483  0.718374  0.164451   \n",
              "\n",
              "       f_06  f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  \\\n",
              "0  0.729857     0     4     1     3     1     2     4     1     5     2     0   \n",
              "1  0.371070     3     0     3     3     5     3     2     0     1     6     0   \n",
              "2  0.767396     3     1     3     2     3     4     1     1     1     0     2   \n",
              "3 -2.020416     2     0     4     5     0     5     1     0     3     1     1   \n",
              "4 -0.936620     1     2     2     2     2     5     0     3     1     1     2   \n",
              "\n",
              "   f_18      f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n",
              "0     1 -3.690715 -0.628005 -2.832295 -1.409039  3.645067  0.233039 -3.754846   \n",
              "1     1  0.664517 -2.871912  3.826628  3.087653  0.494209  3.210875 -0.666457   \n",
              "2     6 -0.494988 -0.946303  2.333223  2.084169 -4.782668 -1.671375  2.774382   \n",
              "3     3 -3.066427 -2.430158 -0.185332 -0.701691 -2.769142 -6.534231 -0.557677   \n",
              "4     4 -1.899984  1.427460 -4.992610  1.154162 -1.931443  2.325042  2.143811   \n",
              "\n",
              "       f_26        f_27        f_28  f_29  f_30  target  \n",
              "0 -1.061733  BDBBCACIBB   20.308715     1     0       0  \n",
              "1  0.123854  ACBDCBCADA -449.291063     1     0       0  \n",
              "2  2.273130  AABBABCLAF  -86.206118     0     1       1  \n",
              "3 -0.429972  ADBBABEEBA  -30.157403     0     2       1  \n",
              "4 -1.039599  ABBBBBCMBB  296.484562     0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cba9613-77d3-4d58-8b63-949a5c73954b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_27</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>493553</td>\n",
              "      <td>0.315471</td>\n",
              "      <td>-0.183690</td>\n",
              "      <td>0.664383</td>\n",
              "      <td>-1.186794</td>\n",
              "      <td>0.665098</td>\n",
              "      <td>0.946208</td>\n",
              "      <td>0.729857</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.690715</td>\n",
              "      <td>-0.628005</td>\n",
              "      <td>-2.832295</td>\n",
              "      <td>-1.409039</td>\n",
              "      <td>3.645067</td>\n",
              "      <td>0.233039</td>\n",
              "      <td>-3.754846</td>\n",
              "      <td>-1.061733</td>\n",
              "      <td>BDBBCACIBB</td>\n",
              "      <td>20.308715</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>237346</td>\n",
              "      <td>-1.286392</td>\n",
              "      <td>1.780592</td>\n",
              "      <td>0.576698</td>\n",
              "      <td>-2.690658</td>\n",
              "      <td>1.321997</td>\n",
              "      <td>-0.675894</td>\n",
              "      <td>0.371070</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.664517</td>\n",
              "      <td>-2.871912</td>\n",
              "      <td>3.826628</td>\n",
              "      <td>3.087653</td>\n",
              "      <td>0.494209</td>\n",
              "      <td>3.210875</td>\n",
              "      <td>-0.666457</td>\n",
              "      <td>0.123854</td>\n",
              "      <td>ACBDCBCADA</td>\n",
              "      <td>-449.291063</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37368</td>\n",
              "      <td>-0.290303</td>\n",
              "      <td>-0.485907</td>\n",
              "      <td>0.808350</td>\n",
              "      <td>-0.156288</td>\n",
              "      <td>1.083632</td>\n",
              "      <td>-1.129914</td>\n",
              "      <td>0.767396</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.494988</td>\n",
              "      <td>-0.946303</td>\n",
              "      <td>2.333223</td>\n",
              "      <td>2.084169</td>\n",
              "      <td>-4.782668</td>\n",
              "      <td>-1.671375</td>\n",
              "      <td>2.774382</td>\n",
              "      <td>2.273130</td>\n",
              "      <td>AABBABCLAF</td>\n",
              "      <td>-86.206118</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>665220</td>\n",
              "      <td>1.243590</td>\n",
              "      <td>0.035112</td>\n",
              "      <td>-1.013236</td>\n",
              "      <td>0.854267</td>\n",
              "      <td>0.019192</td>\n",
              "      <td>0.597892</td>\n",
              "      <td>-2.020416</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-3.066427</td>\n",
              "      <td>-2.430158</td>\n",
              "      <td>-0.185332</td>\n",
              "      <td>-0.701691</td>\n",
              "      <td>-2.769142</td>\n",
              "      <td>-6.534231</td>\n",
              "      <td>-0.557677</td>\n",
              "      <td>-0.429972</td>\n",
              "      <td>ADBBABEEBA</td>\n",
              "      <td>-30.157403</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41499</td>\n",
              "      <td>0.702716</td>\n",
              "      <td>0.817044</td>\n",
              "      <td>-0.064907</td>\n",
              "      <td>-1.045483</td>\n",
              "      <td>0.718374</td>\n",
              "      <td>0.164451</td>\n",
              "      <td>-0.936620</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.899984</td>\n",
              "      <td>1.427460</td>\n",
              "      <td>-4.992610</td>\n",
              "      <td>1.154162</td>\n",
              "      <td>-1.931443</td>\n",
              "      <td>2.325042</td>\n",
              "      <td>2.143811</td>\n",
              "      <td>-1.039599</td>\n",
              "      <td>ABBBBBCMBB</td>\n",
              "      <td>296.484562</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cba9613-77d3-4d58-8b63-949a5c73954b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cba9613-77d3-4d58-8b63-949a5c73954b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cba9613-77d3-4d58-8b63-949a5c73954b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 493553,\n            'f': \"493553\",\n        },\n{\n            'v': 0.3154713179849845,\n            'f': \"0.3154713179849845\",\n        },\n{\n            'v': -0.1836904487704342,\n            'f': \"-0.1836904487704342\",\n        },\n{\n            'v': 0.6643825071902617,\n            'f': \"0.6643825071902617\",\n        },\n{\n            'v': -1.1867943779102057,\n            'f': \"-1.1867943779102057\",\n        },\n{\n            'v': 0.6650983554084389,\n            'f': \"0.6650983554084389\",\n        },\n{\n            'v': 0.946207747620988,\n            'f': \"0.946207747620988\",\n        },\n{\n            'v': 0.7298569499431469,\n            'f': \"0.7298569499431469\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': -3.690715300182188,\n            'f': \"-3.690715300182188\",\n        },\n{\n            'v': -0.6280049668119927,\n            'f': \"-0.6280049668119927\",\n        },\n{\n            'v': -2.832295150712397,\n            'f': \"-2.832295150712397\",\n        },\n{\n            'v': -1.4090385458787378,\n            'f': \"-1.4090385458787378\",\n        },\n{\n            'v': 3.645067262233898,\n            'f': \"3.645067262233898\",\n        },\n{\n            'v': 0.2330390733102534,\n            'f': \"0.2330390733102534\",\n        },\n{\n            'v': -3.754846123350904,\n            'f': \"-3.754846123350904\",\n        },\n{\n            'v': -1.0617332126449046,\n            'f': \"-1.0617332126449046\",\n        },\n\"BDBBCACIBB\",\n{\n            'v': 20.30871493564873,\n            'f': \"20.30871493564873\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 237346,\n            'f': \"237346\",\n        },\n{\n            'v': -1.286392342706846,\n            'f': \"-1.286392342706846\",\n        },\n{\n            'v': 1.7805917149101176,\n            'f': \"1.7805917149101176\",\n        },\n{\n            'v': 0.5766976404384039,\n            'f': \"0.5766976404384039\",\n        },\n{\n            'v': -2.690658095318418,\n            'f': \"-2.690658095318418\",\n        },\n{\n            'v': 1.3219967933572998,\n            'f': \"1.3219967933572998\",\n        },\n{\n            'v': -0.6758939824083278,\n            'f': \"-0.6758939824083278\",\n        },\n{\n            'v': 0.3710700267903256,\n            'f': \"0.3710700267903256\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 6,\n            'f': \"6\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0.6645165908993002,\n            'f': \"0.6645165908993002\",\n        },\n{\n            'v': -2.871912315757452,\n            'f': \"-2.871912315757452\",\n        },\n{\n            'v': 3.826627810842657,\n            'f': \"3.826627810842657\",\n        },\n{\n            'v': 3.087653485668633,\n            'f': \"3.087653485668633\",\n        },\n{\n            'v': 0.4942092665117156,\n            'f': \"0.4942092665117156\",\n        },\n{\n            'v': 3.210874753404081,\n            'f': \"3.210874753404081\",\n        },\n{\n            'v': -0.6664566785948545,\n            'f': \"-0.6664566785948545\",\n        },\n{\n            'v': 0.1238538978213764,\n            'f': \"0.1238538978213764\",\n        },\n\"ACBDCBCADA\",\n{\n            'v': -449.29106308063297,\n            'f': \"-449.29106308063297\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 37368,\n            'f': \"37368\",\n        },\n{\n            'v': -0.2903031581594694,\n            'f': \"-0.2903031581594694\",\n        },\n{\n            'v': -0.4859073078779998,\n            'f': \"-0.4859073078779998\",\n        },\n{\n            'v': 0.8083500053822478,\n            'f': \"0.8083500053822478\",\n        },\n{\n            'v': -0.1562882034675039,\n            'f': \"-0.1562882034675039\",\n        },\n{\n            'v': 1.083631744129082,\n            'f': \"1.083631744129082\",\n        },\n{\n            'v': -1.1299142294071929,\n            'f': \"-1.1299142294071929\",\n        },\n{\n            'v': 0.7673957922691375,\n            'f': \"0.7673957922691375\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 6,\n            'f': \"6\",\n        },\n{\n            'v': -0.4949879257256799,\n            'f': \"-0.4949879257256799\",\n        },\n{\n            'v': -0.9463030178123564,\n            'f': \"-0.9463030178123564\",\n        },\n{\n            'v': 2.3332230088140475,\n            'f': \"2.3332230088140475\",\n        },\n{\n            'v': 2.084169468574978,\n            'f': \"2.084169468574978\",\n        },\n{\n            'v': -4.7826682477273135,\n            'f': \"-4.7826682477273135\",\n        },\n{\n            'v': -1.671374690518444,\n            'f': \"-1.671374690518444\",\n        },\n{\n            'v': 2.7743819671532446,\n            'f': \"2.7743819671532446\",\n        },\n{\n            'v': 2.27312974480488,\n            'f': \"2.27312974480488\",\n        },\n\"AABBABCLAF\",\n{\n            'v': -86.20611797456267,\n            'f': \"-86.20611797456267\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 665220,\n            'f': \"665220\",\n        },\n{\n            'v': 1.2435902764135691,\n            'f': \"1.2435902764135691\",\n        },\n{\n            'v': 0.0351124481295802,\n            'f': \"0.0351124481295802\",\n        },\n{\n            'v': -1.0132364049578737,\n            'f': \"-1.0132364049578737\",\n        },\n{\n            'v': 0.854266756747409,\n            'f': \"0.854266756747409\",\n        },\n{\n            'v': 0.0191923478108258,\n            'f': \"0.0191923478108258\",\n        },\n{\n            'v': 0.5978920134148811,\n            'f': \"0.5978920134148811\",\n        },\n{\n            'v': -2.020416084119066,\n            'f': \"-2.020416084119066\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': -3.066426700596244,\n            'f': \"-3.066426700596244\",\n        },\n{\n            'v': -2.430158197671881,\n            'f': \"-2.430158197671881\",\n        },\n{\n            'v': -0.1853322722460298,\n            'f': \"-0.1853322722460298\",\n        },\n{\n            'v': -0.7016912514931994,\n            'f': \"-0.7016912514931994\",\n        },\n{\n            'v': -2.76914243525596,\n            'f': \"-2.76914243525596\",\n        },\n{\n            'v': -6.534230848040475,\n            'f': \"-6.534230848040475\",\n        },\n{\n            'v': -0.5576772758338957,\n            'f': \"-0.5576772758338957\",\n        },\n{\n            'v': -0.4299722583622913,\n            'f': \"-0.4299722583622913\",\n        },\n\"ADBBABEEBA\",\n{\n            'v': -30.15740300923009,\n            'f': \"-30.15740300923009\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 41499,\n            'f': \"41499\",\n        },\n{\n            'v': 0.7027157143556877,\n            'f': \"0.7027157143556877\",\n        },\n{\n            'v': 0.8170440444671354,\n            'f': \"0.8170440444671354\",\n        },\n{\n            'v': -0.064906742184267,\n            'f': \"-0.064906742184267\",\n        },\n{\n            'v': -1.0454825809420276,\n            'f': \"-1.0454825809420276\",\n        },\n{\n            'v': 0.7183736998235606,\n            'f': \"0.7183736998235606\",\n        },\n{\n            'v': 0.1644514962992729,\n            'f': \"0.1644514962992729\",\n        },\n{\n            'v': -0.9366196529132428,\n            'f': \"-0.9366196529132428\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': -1.8999840497433944,\n            'f': \"-1.8999840497433944\",\n        },\n{\n            'v': 1.4274596343623616,\n            'f': \"1.4274596343623616\",\n        },\n{\n            'v': -4.992609842066788,\n            'f': \"-4.992609842066788\",\n        },\n{\n            'v': 1.154162234302733,\n            'f': \"1.154162234302733\",\n        },\n{\n            'v': -1.9314431250014568,\n            'f': \"-1.9314431250014568\",\n        },\n{\n            'v': 2.3250420992192806,\n            'f': \"2.3250420992192806\",\n        },\n{\n            'v': 2.143810732830162,\n            'f': \"2.143810732830162\",\n        },\n{\n            'v': -1.0395985915012504,\n            'f': \"-1.0395985915012504\",\n        },\n\"ABBBBBCMBB\",\n{\n            'v': 296.4845619201336,\n            'f': \"296.4845619201336\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"number\", \"f_00\"], [\"number\", \"f_01\"], [\"number\", \"f_02\"], [\"number\", \"f_03\"], [\"number\", \"f_04\"], [\"number\", \"f_05\"], [\"number\", \"f_06\"], [\"number\", \"f_07\"], [\"number\", \"f_08\"], [\"number\", \"f_09\"], [\"number\", \"f_10\"], [\"number\", \"f_11\"], [\"number\", \"f_12\"], [\"number\", \"f_13\"], [\"number\", \"f_14\"], [\"number\", \"f_15\"], [\"number\", \"f_16\"], [\"number\", \"f_17\"], [\"number\", \"f_18\"], [\"number\", \"f_19\"], [\"number\", \"f_20\"], [\"number\", \"f_21\"], [\"number\", \"f_22\"], [\"number\", \"f_23\"], [\"number\", \"f_24\"], [\"number\", \"f_25\"], [\"number\", \"f_26\"], [\"string\", \"f_27\"], [\"number\", \"f_28\"], [\"number\", \"f_29\"], [\"number\", \"f_30\"], [\"number\", \"target\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "csv_path = Path('/content/drive/MyDrive/train.csv') if IN_COLAB else Path('../Data/train.csv')\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AVt-KnvPepg"
      },
      "source": [
        "## First approuch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlPl0dVDrByn"
      },
      "outputs": [],
      "source": [
        "X, y = df.drop(['target', 'f_27', 'id'], axis=1), df['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "26pKNWPurBwZ",
        "outputId": "d86646d1-3361-4e42-d119-a949102f62ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "      <td>810000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.001564</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>-0.001910</td>\n",
              "      <td>-0.000820</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>-0.000971</td>\n",
              "      <td>2.032086</td>\n",
              "      <td>2.057980</td>\n",
              "      <td>2.362590</td>\n",
              "      <td>2.177847</td>\n",
              "      <td>1.804038</td>\n",
              "      <td>2.842322</td>\n",
              "      <td>2.239307</td>\n",
              "      <td>1.515411</td>\n",
              "      <td>2.101359</td>\n",
              "      <td>2.096502</td>\n",
              "      <td>1.857758</td>\n",
              "      <td>2.065975</td>\n",
              "      <td>0.307220</td>\n",
              "      <td>-0.178796</td>\n",
              "      <td>-0.156877</td>\n",
              "      <td>-0.009749</td>\n",
              "      <td>-0.369114</td>\n",
              "      <td>-0.342708</td>\n",
              "      <td>0.175932</td>\n",
              "      <td>0.356640</td>\n",
              "      <td>-0.448086</td>\n",
              "      <td>0.345565</td>\n",
              "      <td>1.002373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.998719</td>\n",
              "      <td>0.999402</td>\n",
              "      <td>1.000892</td>\n",
              "      <td>1.000081</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999535</td>\n",
              "      <td>1.656749</td>\n",
              "      <td>1.590698</td>\n",
              "      <td>1.637473</td>\n",
              "      <td>1.645519</td>\n",
              "      <td>1.537589</td>\n",
              "      <td>1.762672</td>\n",
              "      <td>1.537712</td>\n",
              "      <td>1.359798</td>\n",
              "      <td>1.568952</td>\n",
              "      <td>1.559978</td>\n",
              "      <td>1.467507</td>\n",
              "      <td>1.565593</td>\n",
              "      <td>2.314858</td>\n",
              "      <td>2.400672</td>\n",
              "      <td>2.484487</td>\n",
              "      <td>2.450494</td>\n",
              "      <td>2.454113</td>\n",
              "      <td>2.387102</td>\n",
              "      <td>2.416753</td>\n",
              "      <td>2.476792</td>\n",
              "      <td>238.735832</td>\n",
              "      <td>0.475553</td>\n",
              "      <td>0.818851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.599856</td>\n",
              "      <td>-4.682199</td>\n",
              "      <td>-4.642676</td>\n",
              "      <td>-4.628484</td>\n",
              "      <td>-4.748501</td>\n",
              "      <td>-4.750214</td>\n",
              "      <td>-4.842919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-11.280941</td>\n",
              "      <td>-11.257917</td>\n",
              "      <td>-12.183785</td>\n",
              "      <td>-11.853530</td>\n",
              "      <td>-12.301097</td>\n",
              "      <td>-11.416189</td>\n",
              "      <td>-11.918306</td>\n",
              "      <td>-14.300577</td>\n",
              "      <td>-1229.753052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.674386</td>\n",
              "      <td>-0.674814</td>\n",
              "      <td>-0.674948</td>\n",
              "      <td>-0.676899</td>\n",
              "      <td>-0.676212</td>\n",
              "      <td>-0.672953</td>\n",
              "      <td>-0.675204</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.236465</td>\n",
              "      <td>-1.804803</td>\n",
              "      <td>-1.819358</td>\n",
              "      <td>-1.645711</td>\n",
              "      <td>-2.019762</td>\n",
              "      <td>-1.956021</td>\n",
              "      <td>-1.440454</td>\n",
              "      <td>-1.262614</td>\n",
              "      <td>-159.456219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.002005</td>\n",
              "      <td>0.002531</td>\n",
              "      <td>0.001148</td>\n",
              "      <td>-0.002556</td>\n",
              "      <td>-0.001907</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>-0.001630</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.329103</td>\n",
              "      <td>-0.189919</td>\n",
              "      <td>-0.153055</td>\n",
              "      <td>0.030148</td>\n",
              "      <td>-0.390120</td>\n",
              "      <td>-0.342316</td>\n",
              "      <td>0.160621</td>\n",
              "      <td>0.405216</td>\n",
              "      <td>-0.573352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.674684</td>\n",
              "      <td>0.675737</td>\n",
              "      <td>0.676736</td>\n",
              "      <td>0.671851</td>\n",
              "      <td>0.672968</td>\n",
              "      <td>0.675826</td>\n",
              "      <td>0.673790</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.878621</td>\n",
              "      <td>1.444271</td>\n",
              "      <td>1.506658</td>\n",
              "      <td>1.660455</td>\n",
              "      <td>1.257267</td>\n",
              "      <td>1.266450</td>\n",
              "      <td>1.794780</td>\n",
              "      <td>2.028263</td>\n",
              "      <td>158.941960</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.749301</td>\n",
              "      <td>4.815699</td>\n",
              "      <td>4.961982</td>\n",
              "      <td>4.454920</td>\n",
              "      <td>4.948983</td>\n",
              "      <td>4.971881</td>\n",
              "      <td>4.822668</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>11.108150</td>\n",
              "      <td>11.475325</td>\n",
              "      <td>12.029242</td>\n",
              "      <td>11.344080</td>\n",
              "      <td>12.247100</td>\n",
              "      <td>12.389844</td>\n",
              "      <td>12.529179</td>\n",
              "      <td>12.913041</td>\n",
              "      <td>1229.562577</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                f_00           f_01           f_02           f_03  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        0.000368       0.001564       0.000306      -0.001910   \n",
              "std         0.998719       0.999402       1.000892       1.000081   \n",
              "min        -4.599856      -4.682199      -4.642676      -4.628484   \n",
              "25%        -0.674386      -0.674814      -0.674948      -0.676899   \n",
              "50%         0.002005       0.002531       0.001148      -0.002556   \n",
              "75%         0.674684       0.675737       0.676736       0.671851   \n",
              "max         4.749301       4.815699       4.961982       4.454920   \n",
              "\n",
              "                f_04           f_05           f_06           f_07  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean       -0.000820       0.000644      -0.000971       2.032086   \n",
              "std         1.000000       0.999999       0.999535       1.656749   \n",
              "min        -4.748501      -4.750214      -4.842919       0.000000   \n",
              "25%        -0.676212      -0.672953      -0.675204       1.000000   \n",
              "50%        -0.001907       0.000071      -0.001630       2.000000   \n",
              "75%         0.672968       0.675826       0.673790       3.000000   \n",
              "max         4.948983       4.971881       4.822668      15.000000   \n",
              "\n",
              "                f_08           f_09           f_10           f_11  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        2.057980       2.362590       2.177847       1.804038   \n",
              "std         1.590698       1.637473       1.645519       1.537589   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       1.000000       1.000000   \n",
              "50%         2.000000       2.000000       2.000000       2.000000   \n",
              "75%         3.000000       3.000000       3.000000       3.000000   \n",
              "max        16.000000      14.000000      14.000000      13.000000   \n",
              "\n",
              "                f_12           f_13           f_14           f_15  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        2.842322       2.239307       1.515411       2.101359   \n",
              "std         1.762672       1.537712       1.359798       1.568952   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         2.000000       1.000000       0.000000       1.000000   \n",
              "50%         3.000000       2.000000       1.000000       2.000000   \n",
              "75%         4.000000       3.000000       2.000000       3.000000   \n",
              "max        16.000000      12.000000      14.000000      14.000000   \n",
              "\n",
              "                f_16           f_17           f_18           f_19  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean        2.096502       1.857758       2.065975       0.307220   \n",
              "std         1.559978       1.467507       1.565593       2.314858   \n",
              "min         0.000000       0.000000       0.000000     -11.280941   \n",
              "25%         1.000000       1.000000       1.000000      -1.236465   \n",
              "50%         2.000000       2.000000       2.000000       0.329103   \n",
              "75%         3.000000       3.000000       3.000000       1.878621   \n",
              "max        15.000000      12.000000      13.000000      11.108150   \n",
              "\n",
              "                f_20           f_21           f_22           f_23  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean       -0.178796      -0.156877      -0.009749      -0.369114   \n",
              "std         2.400672       2.484487       2.450494       2.454113   \n",
              "min       -11.257917     -12.183785     -11.853530     -12.301097   \n",
              "25%        -1.804803      -1.819358      -1.645711      -2.019762   \n",
              "50%        -0.189919      -0.153055       0.030148      -0.390120   \n",
              "75%         1.444271       1.506658       1.660455       1.257267   \n",
              "max        11.475325      12.029242      11.344080      12.247100   \n",
              "\n",
              "                f_24           f_25           f_26           f_28  \\\n",
              "count  810000.000000  810000.000000  810000.000000  810000.000000   \n",
              "mean       -0.342708       0.175932       0.356640      -0.448086   \n",
              "std         2.387102       2.416753       2.476792     238.735832   \n",
              "min       -11.416189     -11.918306     -14.300577   -1229.753052   \n",
              "25%        -1.956021      -1.440454      -1.262614    -159.456219   \n",
              "50%        -0.342316       0.160621       0.405216      -0.573352   \n",
              "75%         1.266450       1.794780       2.028263     158.941960   \n",
              "max        12.389844      12.529179      12.913041    1229.562577   \n",
              "\n",
              "                f_29           f_30  \n",
              "count  810000.000000  810000.000000  \n",
              "mean        0.345565       1.002373  \n",
              "std         0.475553       0.818851  \n",
              "min         0.000000       0.000000  \n",
              "25%         0.000000       0.000000  \n",
              "50%         0.000000       1.000000  \n",
              "75%         1.000000       2.000000  \n",
              "max         1.000000       2.000000  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmznjs5grBnV",
        "outputId": "c7388ce9-7b1c-4dfc-c48a-4b832222cc6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    415945\n",
              "1    394055\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nc_P-uEg4BZ",
        "outputId": "da2894c5-9823-461f-ec2f-33f130e7e10b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame, pandas.core.series.Series)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X), type(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6xuWymPQrBd_"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, input_features=30):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(in_features=input_features, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=128, out_features=128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=128, out_features=128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=128, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.main(x)\n",
        "\n",
        "# Define a custom dataset by extending the PyTorch Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels \n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        label = self.labels[index]\n",
        "        if self.transform:\n",
        "            item = self.transform(item)\n",
        "        return item, label\n",
        "    \n",
        "def datasets(dataset, stratify, test_size):\n",
        "    train_size = 1 - test_size\n",
        "\n",
        "    # Stratify by label\n",
        "    labels = np.array(stratify)\n",
        "    positive_indices = np.where(labels == 1)[0]\n",
        "    negative_indices = np.where(labels == 0)[0]\n",
        "\n",
        "    positive_split = int(train_size * len(positive_indices))\n",
        "    negative_split = int(train_size * len(negative_indices))\n",
        "\n",
        "    positive_train_indices = positive_indices[:positive_split]\n",
        "    positive_test_indices = positive_indices[positive_split:]\n",
        "    negative_train_indices = negative_indices[:negative_split]\n",
        "    negative_test_indices = negative_indices[negative_split:]\n",
        "\n",
        "    train_indices = np.concatenate([positive_train_indices, negative_train_indices])\n",
        "    test_indices = np.concatenate([positive_test_indices, negative_test_indices])\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "    \n",
        "    return train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b1ydxiAPepj",
        "outputId": "dbabf924-3388-44d0-ece1-6a36e9ec26f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.315508</td>\n",
              "      <td>-0.185365</td>\n",
              "      <td>0.663485</td>\n",
              "      <td>-1.184789</td>\n",
              "      <td>0.665919</td>\n",
              "      <td>0.945566</td>\n",
              "      <td>0.731168</td>\n",
              "      <td>-1.226551</td>\n",
              "      <td>1.220861</td>\n",
              "      <td>-0.832130</td>\n",
              "      <td>0.499632</td>\n",
              "      <td>-0.522922</td>\n",
              "      <td>-0.477867</td>\n",
              "      <td>1.145009</td>\n",
              "      <td>-0.379035</td>\n",
              "      <td>1.847503</td>\n",
              "      <td>-0.061861</td>\n",
              "      <td>-1.265929</td>\n",
              "      <td>-0.680877</td>\n",
              "      <td>-1.727077</td>\n",
              "      <td>-0.187118</td>\n",
              "      <td>-1.076850</td>\n",
              "      <td>-0.571024</td>\n",
              "      <td>1.635696</td>\n",
              "      <td>0.241191</td>\n",
              "      <td>-1.626472</td>\n",
              "      <td>-0.572666</td>\n",
              "      <td>0.086945</td>\n",
              "      <td>1.376157</td>\n",
              "      <td>-1.224123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.288412</td>\n",
              "      <td>1.780094</td>\n",
              "      <td>0.575879</td>\n",
              "      <td>-2.688532</td>\n",
              "      <td>1.322818</td>\n",
              "      <td>-0.676539</td>\n",
              "      <td>0.372214</td>\n",
              "      <td>0.584225</td>\n",
              "      <td>-1.293760</td>\n",
              "      <td>0.389265</td>\n",
              "      <td>0.499632</td>\n",
              "      <td>2.078555</td>\n",
              "      <td>0.089454</td>\n",
              "      <td>-0.155626</td>\n",
              "      <td>-1.114439</td>\n",
              "      <td>-0.701972</td>\n",
              "      <td>2.502279</td>\n",
              "      <td>-1.265929</td>\n",
              "      <td>-0.680877</td>\n",
              "      <td>0.154349</td>\n",
              "      <td>-1.121819</td>\n",
              "      <td>1.603352</td>\n",
              "      <td>1.263992</td>\n",
              "      <td>0.351786</td>\n",
              "      <td>1.488661</td>\n",
              "      <td>-0.348562</td>\n",
              "      <td>-0.093987</td>\n",
              "      <td>-1.880083</td>\n",
              "      <td>1.376157</td>\n",
              "      <td>-1.224123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.291044</td>\n",
              "      <td>-0.487763</td>\n",
              "      <td>0.807325</td>\n",
              "      <td>-0.154365</td>\n",
              "      <td>1.084453</td>\n",
              "      <td>-1.130560</td>\n",
              "      <td>0.768724</td>\n",
              "      <td>0.584225</td>\n",
              "      <td>-0.665105</td>\n",
              "      <td>0.389265</td>\n",
              "      <td>-0.108080</td>\n",
              "      <td>0.777817</td>\n",
              "      <td>0.656775</td>\n",
              "      <td>-0.805943</td>\n",
              "      <td>-0.379035</td>\n",
              "      <td>-0.701972</td>\n",
              "      <td>-1.343932</td>\n",
              "      <td>0.096928</td>\n",
              "      <td>2.512803</td>\n",
              "      <td>-0.346548</td>\n",
              "      <td>-0.319705</td>\n",
              "      <td>1.002260</td>\n",
              "      <td>0.854489</td>\n",
              "      <td>-1.798432</td>\n",
              "      <td>-0.556603</td>\n",
              "      <td>1.075183</td>\n",
              "      <td>0.773779</td>\n",
              "      <td>-0.359217</td>\n",
              "      <td>-0.726661</td>\n",
              "      <td>-0.002898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.244818</td>\n",
              "      <td>0.033569</td>\n",
              "      <td>-1.012640</td>\n",
              "      <td>0.856109</td>\n",
              "      <td>0.020013</td>\n",
              "      <td>0.597249</td>\n",
              "      <td>-2.020385</td>\n",
              "      <td>-0.019367</td>\n",
              "      <td>-1.293760</td>\n",
              "      <td>0.999962</td>\n",
              "      <td>1.715054</td>\n",
              "      <td>-1.173291</td>\n",
              "      <td>1.224096</td>\n",
              "      <td>-0.805943</td>\n",
              "      <td>-1.114439</td>\n",
              "      <td>0.572765</td>\n",
              "      <td>-0.702897</td>\n",
              "      <td>-0.584500</td>\n",
              "      <td>0.596595</td>\n",
              "      <td>-1.457389</td>\n",
              "      <td>-0.937806</td>\n",
              "      <td>-0.011453</td>\n",
              "      <td>-0.282369</td>\n",
              "      <td>-0.977962</td>\n",
              "      <td>-2.593742</td>\n",
              "      <td>-0.303552</td>\n",
              "      <td>-0.317593</td>\n",
              "      <td>-0.124444</td>\n",
              "      <td>-0.726661</td>\n",
              "      <td>1.218327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.703249</td>\n",
              "      <td>0.815969</td>\n",
              "      <td>-0.065154</td>\n",
              "      <td>-1.043488</td>\n",
              "      <td>0.719195</td>\n",
              "      <td>0.163808</td>\n",
              "      <td>-0.936084</td>\n",
              "      <td>-0.622959</td>\n",
              "      <td>-0.036450</td>\n",
              "      <td>-0.221433</td>\n",
              "      <td>-0.108080</td>\n",
              "      <td>0.127447</td>\n",
              "      <td>1.224096</td>\n",
              "      <td>-1.456260</td>\n",
              "      <td>1.091772</td>\n",
              "      <td>-0.701972</td>\n",
              "      <td>-0.702897</td>\n",
              "      <td>0.096928</td>\n",
              "      <td>1.235331</td>\n",
              "      <td>-0.953495</td>\n",
              "      <td>0.669086</td>\n",
              "      <td>-1.946372</td>\n",
              "      <td>0.474970</td>\n",
              "      <td>-0.636617</td>\n",
              "      <td>1.117569</td>\n",
              "      <td>0.814266</td>\n",
              "      <td>-0.563729</td>\n",
              "      <td>1.243772</td>\n",
              "      <td>-0.726661</td>\n",
              "      <td>1.218327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
              "0  0.315508 -0.185365  0.663485 -1.184789  0.665919  0.945566  0.731168   \n",
              "1 -1.288412  1.780094  0.575879 -2.688532  1.322818 -0.676539  0.372214   \n",
              "2 -0.291044 -0.487763  0.807325 -0.154365  1.084453 -1.130560  0.768724   \n",
              "3  1.244818  0.033569 -1.012640  0.856109  0.020013  0.597249 -2.020385   \n",
              "4  0.703249  0.815969 -0.065154 -1.043488  0.719195  0.163808 -0.936084   \n",
              "\n",
              "       f_07      f_08      f_09      f_10      f_11      f_12      f_13  \\\n",
              "0 -1.226551  1.220861 -0.832130  0.499632 -0.522922 -0.477867  1.145009   \n",
              "1  0.584225 -1.293760  0.389265  0.499632  2.078555  0.089454 -0.155626   \n",
              "2  0.584225 -0.665105  0.389265 -0.108080  0.777817  0.656775 -0.805943   \n",
              "3 -0.019367 -1.293760  0.999962  1.715054 -1.173291  1.224096 -0.805943   \n",
              "4 -0.622959 -0.036450 -0.221433 -0.108080  0.127447  1.224096 -1.456260   \n",
              "\n",
              "       f_14      f_15      f_16      f_17      f_18      f_19      f_20  \\\n",
              "0 -0.379035  1.847503 -0.061861 -1.265929 -0.680877 -1.727077 -0.187118   \n",
              "1 -1.114439 -0.701972  2.502279 -1.265929 -0.680877  0.154349 -1.121819   \n",
              "2 -0.379035 -0.701972 -1.343932  0.096928  2.512803 -0.346548 -0.319705   \n",
              "3 -1.114439  0.572765 -0.702897 -0.584500  0.596595 -1.457389 -0.937806   \n",
              "4  1.091772 -0.701972 -0.702897  0.096928  1.235331 -0.953495  0.669086   \n",
              "\n",
              "       f_21      f_22      f_23      f_24      f_25      f_26      f_28  \\\n",
              "0 -1.076850 -0.571024  1.635696  0.241191 -1.626472 -0.572666  0.086945   \n",
              "1  1.603352  1.263992  0.351786  1.488661 -0.348562 -0.093987 -1.880083   \n",
              "2  1.002260  0.854489 -1.798432 -0.556603  1.075183  0.773779 -0.359217   \n",
              "3 -0.011453 -0.282369 -0.977962 -2.593742 -0.303552 -0.317593 -0.124444   \n",
              "4 -1.946372  0.474970 -0.636617  1.117569  0.814266 -0.563729  1.243772   \n",
              "\n",
              "       f_29      f_30  \n",
              "0  1.376157 -1.224123  \n",
              "1  1.376157 -1.224123  \n",
              "2 -0.726661 -0.002898  \n",
              "3 -0.726661  1.218327  \n",
              "4 -0.726661  1.218327  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_R50gWyPepk",
        "outputId": "9498d4f0-73fe-43ab-ec72-e09ed1110c11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "      <td>8.100000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.277222e-17</td>\n",
              "      <td>-2.741291e-18</td>\n",
              "      <td>-1.000900e-17</td>\n",
              "      <td>-7.184377e-18</td>\n",
              "      <td>2.745677e-18</td>\n",
              "      <td>-9.684434e-18</td>\n",
              "      <td>-1.142132e-17</td>\n",
              "      <td>-5.172049e-17</td>\n",
              "      <td>-1.485648e-16</td>\n",
              "      <td>6.184353e-17</td>\n",
              "      <td>6.965073e-17</td>\n",
              "      <td>-3.005333e-17</td>\n",
              "      <td>1.459683e-17</td>\n",
              "      <td>-1.030901e-16</td>\n",
              "      <td>9.513378e-17</td>\n",
              "      <td>-6.732612e-17</td>\n",
              "      <td>1.230906e-16</td>\n",
              "      <td>-1.571966e-17</td>\n",
              "      <td>-6.828228e-17</td>\n",
              "      <td>-7.308941e-17</td>\n",
              "      <td>1.747409e-17</td>\n",
              "      <td>-2.929892e-18</td>\n",
              "      <td>-4.035181e-18</td>\n",
              "      <td>-2.333387e-18</td>\n",
              "      <td>1.224590e-17</td>\n",
              "      <td>3.477273e-17</td>\n",
              "      <td>7.921236e-17</td>\n",
              "      <td>-1.642143e-17</td>\n",
              "      <td>1.593019e-17</td>\n",
              "      <td>-1.786445e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>1.000001e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.606128e+00</td>\n",
              "      <td>-4.686569e+00</td>\n",
              "      <td>-4.638847e+00</td>\n",
              "      <td>-4.626203e+00</td>\n",
              "      <td>-4.747684e+00</td>\n",
              "      <td>-4.750866e+00</td>\n",
              "      <td>-4.844201e+00</td>\n",
              "      <td>-1.226551e+00</td>\n",
              "      <td>-1.293760e+00</td>\n",
              "      <td>-1.442828e+00</td>\n",
              "      <td>-1.323502e+00</td>\n",
              "      <td>-1.173291e+00</td>\n",
              "      <td>-1.612509e+00</td>\n",
              "      <td>-1.456260e+00</td>\n",
              "      <td>-1.114439e+00</td>\n",
              "      <td>-1.339340e+00</td>\n",
              "      <td>-1.343932e+00</td>\n",
              "      <td>-1.265929e+00</td>\n",
              "      <td>-1.319613e+00</td>\n",
              "      <td>-5.005996e+00</td>\n",
              "      <td>-4.615012e+00</td>\n",
              "      <td>-4.840804e+00</td>\n",
              "      <td>-4.833224e+00</td>\n",
              "      <td>-4.862037e+00</td>\n",
              "      <td>-4.638884e+00</td>\n",
              "      <td>-5.004338e+00</td>\n",
              "      <td>-5.917825e+00</td>\n",
              "      <td>-5.149230e+00</td>\n",
              "      <td>-7.266613e-01</td>\n",
              "      <td>-1.224123e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.756203e-01</td>\n",
              "      <td>-6.767832e-01</td>\n",
              "      <td>-6.746520e-01</td>\n",
              "      <td>-6.749347e-01</td>\n",
              "      <td>-6.753925e-01</td>\n",
              "      <td>-6.735980e-01</td>\n",
              "      <td>-6.745475e-01</td>\n",
              "      <td>-6.229591e-01</td>\n",
              "      <td>-6.651048e-01</td>\n",
              "      <td>-8.321305e-01</td>\n",
              "      <td>-7.157908e-01</td>\n",
              "      <td>-5.229217e-01</td>\n",
              "      <td>-4.778670e-01</td>\n",
              "      <td>-8.059429e-01</td>\n",
              "      <td>-1.114439e+00</td>\n",
              "      <td>-7.019718e-01</td>\n",
              "      <td>-7.028966e-01</td>\n",
              "      <td>-5.845004e-01</td>\n",
              "      <td>-6.808767e-01</td>\n",
              "      <td>-6.668599e-01</td>\n",
              "      <td>-6.773138e-01</td>\n",
              "      <td>-6.691450e-01</td>\n",
              "      <td>-6.676056e-01</td>\n",
              "      <td>-6.726050e-01</td>\n",
              "      <td>-6.758463e-01</td>\n",
              "      <td>-6.688259e-01</td>\n",
              "      <td>-6.537707e-01</td>\n",
              "      <td>-6.660426e-01</td>\n",
              "      <td>-7.266613e-01</td>\n",
              "      <td>-1.224123e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.639482e-03</td>\n",
              "      <td>9.684993e-04</td>\n",
              "      <td>8.415122e-04</td>\n",
              "      <td>-6.451620e-04</td>\n",
              "      <td>-1.086850e-03</td>\n",
              "      <td>-5.721649e-04</td>\n",
              "      <td>-6.598558e-04</td>\n",
              "      <td>-1.936711e-02</td>\n",
              "      <td>-3.644958e-02</td>\n",
              "      <td>-2.214329e-01</td>\n",
              "      <td>-1.080796e-01</td>\n",
              "      <td>1.274475e-01</td>\n",
              "      <td>8.945390e-02</td>\n",
              "      <td>-1.556257e-01</td>\n",
              "      <td>-3.790352e-01</td>\n",
              "      <td>-6.460321e-02</td>\n",
              "      <td>-6.186147e-02</td>\n",
              "      <td>9.692768e-02</td>\n",
              "      <td>-4.214080e-02</td>\n",
              "      <td>9.453292e-03</td>\n",
              "      <td>-4.633341e-03</td>\n",
              "      <td>1.538327e-03</td>\n",
              "      <td>1.628116e-02</td>\n",
              "      <td>-8.559671e-03</td>\n",
              "      <td>1.643847e-04</td>\n",
              "      <td>-6.335318e-03</td>\n",
              "      <td>1.961251e-02</td>\n",
              "      <td>-5.247088e-04</td>\n",
              "      <td>-7.266613e-01</td>\n",
              "      <td>-2.897771e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.751812e-01</td>\n",
              "      <td>6.745771e-01</td>\n",
              "      <td>6.758278e-01</td>\n",
              "      <td>6.737077e-01</td>\n",
              "      <td>6.737887e-01</td>\n",
              "      <td>6.751838e-01</td>\n",
              "      <td>6.750750e-01</td>\n",
              "      <td>5.842249e-01</td>\n",
              "      <td>5.922056e-01</td>\n",
              "      <td>3.892647e-01</td>\n",
              "      <td>4.996316e-01</td>\n",
              "      <td>7.778166e-01</td>\n",
              "      <td>6.567748e-01</td>\n",
              "      <td>4.946915e-01</td>\n",
              "      <td>3.563685e-01</td>\n",
              "      <td>5.727654e-01</td>\n",
              "      <td>5.791736e-01</td>\n",
              "      <td>7.783558e-01</td>\n",
              "      <td>5.965951e-01</td>\n",
              "      <td>6.788330e-01</td>\n",
              "      <td>6.760890e-01</td>\n",
              "      <td>6.695690e-01</td>\n",
              "      <td>6.815786e-01</td>\n",
              "      <td>6.627166e-01</td>\n",
              "      <td>6.741058e-01</td>\n",
              "      <td>6.698445e-01</td>\n",
              "      <td>6.749149e-01</td>\n",
              "      <td>6.676423e-01</td>\n",
              "      <td>1.376157e+00</td>\n",
              "      <td>1.218327e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.755027e+00</td>\n",
              "      <td>4.817020e+00</td>\n",
              "      <td>4.957258e+00</td>\n",
              "      <td>4.456473e+00</td>\n",
              "      <td>4.949807e+00</td>\n",
              "      <td>4.971246e+00</td>\n",
              "      <td>4.825883e+00</td>\n",
              "      <td>7.827329e+00</td>\n",
              "      <td>8.764723e+00</td>\n",
              "      <td>7.106938e+00</td>\n",
              "      <td>7.184455e+00</td>\n",
              "      <td>7.281508e+00</td>\n",
              "      <td>7.464626e+00</td>\n",
              "      <td>6.347546e+00</td>\n",
              "      <td>9.181213e+00</td>\n",
              "      <td>7.583820e+00</td>\n",
              "      <td>8.271595e+00</td>\n",
              "      <td>6.911209e+00</td>\n",
              "      <td>6.983954e+00</td>\n",
              "      <td>4.665918e+00</td>\n",
              "      <td>4.854528e+00</td>\n",
              "      <td>4.904886e+00</td>\n",
              "      <td>4.633284e+00</td>\n",
              "      <td>5.140847e+00</td>\n",
              "      <td>5.333899e+00</td>\n",
              "      <td>5.111510e+00</td>\n",
              "      <td>5.069625e+00</td>\n",
              "      <td>5.152186e+00</td>\n",
              "      <td>1.376157e+00</td>\n",
              "      <td>1.218327e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               f_00          f_01          f_02          f_03          f_04  \\\n",
              "count  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05   \n",
              "mean   1.277222e-17 -2.741291e-18 -1.000900e-17 -7.184377e-18  2.745677e-18   \n",
              "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
              "min   -4.606128e+00 -4.686569e+00 -4.638847e+00 -4.626203e+00 -4.747684e+00   \n",
              "25%   -6.756203e-01 -6.767832e-01 -6.746520e-01 -6.749347e-01 -6.753925e-01   \n",
              "50%    1.639482e-03  9.684993e-04  8.415122e-04 -6.451620e-04 -1.086850e-03   \n",
              "75%    6.751812e-01  6.745771e-01  6.758278e-01  6.737077e-01  6.737887e-01   \n",
              "max    4.755027e+00  4.817020e+00  4.957258e+00  4.456473e+00  4.949807e+00   \n",
              "\n",
              "               f_05          f_06          f_07          f_08          f_09  \\\n",
              "count  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05   \n",
              "mean  -9.684434e-18 -1.142132e-17 -5.172049e-17 -1.485648e-16  6.184353e-17   \n",
              "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
              "min   -4.750866e+00 -4.844201e+00 -1.226551e+00 -1.293760e+00 -1.442828e+00   \n",
              "25%   -6.735980e-01 -6.745475e-01 -6.229591e-01 -6.651048e-01 -8.321305e-01   \n",
              "50%   -5.721649e-04 -6.598558e-04 -1.936711e-02 -3.644958e-02 -2.214329e-01   \n",
              "75%    6.751838e-01  6.750750e-01  5.842249e-01  5.922056e-01  3.892647e-01   \n",
              "max    4.971246e+00  4.825883e+00  7.827329e+00  8.764723e+00  7.106938e+00   \n",
              "\n",
              "               f_10          f_11          f_12          f_13          f_14  \\\n",
              "count  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05   \n",
              "mean   6.965073e-17 -3.005333e-17  1.459683e-17 -1.030901e-16  9.513378e-17   \n",
              "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
              "min   -1.323502e+00 -1.173291e+00 -1.612509e+00 -1.456260e+00 -1.114439e+00   \n",
              "25%   -7.157908e-01 -5.229217e-01 -4.778670e-01 -8.059429e-01 -1.114439e+00   \n",
              "50%   -1.080796e-01  1.274475e-01  8.945390e-02 -1.556257e-01 -3.790352e-01   \n",
              "75%    4.996316e-01  7.778166e-01  6.567748e-01  4.946915e-01  3.563685e-01   \n",
              "max    7.184455e+00  7.281508e+00  7.464626e+00  6.347546e+00  9.181213e+00   \n",
              "\n",
              "               f_15          f_16          f_17          f_18          f_19  \\\n",
              "count  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05   \n",
              "mean  -6.732612e-17  1.230906e-16 -1.571966e-17 -6.828228e-17 -7.308941e-17   \n",
              "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
              "min   -1.339340e+00 -1.343932e+00 -1.265929e+00 -1.319613e+00 -5.005996e+00   \n",
              "25%   -7.019718e-01 -7.028966e-01 -5.845004e-01 -6.808767e-01 -6.668599e-01   \n",
              "50%   -6.460321e-02 -6.186147e-02  9.692768e-02 -4.214080e-02  9.453292e-03   \n",
              "75%    5.727654e-01  5.791736e-01  7.783558e-01  5.965951e-01  6.788330e-01   \n",
              "max    7.583820e+00  8.271595e+00  6.911209e+00  6.983954e+00  4.665918e+00   \n",
              "\n",
              "               f_20          f_21          f_22          f_23          f_24  \\\n",
              "count  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05   \n",
              "mean   1.747409e-17 -2.929892e-18 -4.035181e-18 -2.333387e-18  1.224590e-17   \n",
              "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
              "min   -4.615012e+00 -4.840804e+00 -4.833224e+00 -4.862037e+00 -4.638884e+00   \n",
              "25%   -6.773138e-01 -6.691450e-01 -6.676056e-01 -6.726050e-01 -6.758463e-01   \n",
              "50%   -4.633341e-03  1.538327e-03  1.628116e-02 -8.559671e-03  1.643847e-04   \n",
              "75%    6.760890e-01  6.695690e-01  6.815786e-01  6.627166e-01  6.741058e-01   \n",
              "max    4.854528e+00  4.904886e+00  4.633284e+00  5.140847e+00  5.333899e+00   \n",
              "\n",
              "               f_25          f_26          f_28          f_29          f_30  \n",
              "count  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  8.100000e+05  \n",
              "mean   3.477273e-17  7.921236e-17 -1.642143e-17  1.593019e-17 -1.786445e-17  \n",
              "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  \n",
              "min   -5.004338e+00 -5.917825e+00 -5.149230e+00 -7.266613e-01 -1.224123e+00  \n",
              "25%   -6.688259e-01 -6.537707e-01 -6.660426e-01 -7.266613e-01 -1.224123e+00  \n",
              "50%   -6.335318e-03  1.961251e-02 -5.247088e-04 -7.266613e-01 -2.897771e-03  \n",
              "75%    6.698445e-01  6.749149e-01  6.676423e-01  1.376157e+00  1.218327e+00  \n",
              "max    5.111510e+00  5.069625e+00  5.152186e+00  1.376157e+00  1.218327e+00  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceGWFcgVykIZ",
        "outputId": "ec70c167-98c6-46a7-c0f2-caba39de43c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "810000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Declare the hole dataset\n",
        "X_tensor, y_tensor = torch.from_numpy(X.to_numpy()), torch.from_numpy(y.to_numpy())\n",
        "X_tensor, y_tensor = X_tensor.type(torch.float), y_tensor.type(torch.float)\n",
        "dataset = CustomDataset(data=X_tensor, labels=y_tensor)\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LkKFcbPwlHM",
        "outputId": "85d89a77-8ae2-4c36-9539-e21087a8e438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(688499, 121501)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset, test_dataset = datasets(dataset, y, test_size=0.15)\n",
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KUnpQLqcwylO"
      },
      "outputs": [],
      "source": [
        "# Checkpoint\n",
        "def checkpoint(epoch, model, optimizer, criteria, save_as: Path):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'criteria': criteria,\n",
        "    }, save_as)\n",
        "    \n",
        "\n",
        "# Validate\n",
        "def validation(model, device, valid_loader, criteria):\n",
        "    # Settings\n",
        "    model.eval()\n",
        "    loss_total = 0\n",
        "    accuracy_total = 0\n",
        "\n",
        "    # Test validation data\n",
        "    with torch.inference_mode():\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs).squeeze(dim=1)\n",
        "            loss = criteria(outputs, labels)\n",
        "            loss_total += loss.item() * inputs.size(0)\n",
        "            matches = torch.round(torch.sigmoid(outputs)) == labels\n",
        "            accuracy_total += (torch.sum(matches.to(torch.int32))).item()\n",
        "                        \n",
        "    return (loss_total / len(valid_loader), accuracy_total / len(valid_loader.dataset))\n",
        "\n",
        "\n",
        "# Train\n",
        "def train(device, model, epochs, optimizer, criteria, train_loader, valid_loader, resume=1, save_as=Path('../Output/model.pth')):\n",
        "    # Early stopping\n",
        "    last_loss = 100\n",
        "    patience = 5\n",
        "    trigger_times = 0\n",
        "    \n",
        "    train_loss_track, train_accuracy_track = [], []\n",
        "    test_loss_track, test_accuracy_track = [], []\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(resume, epochs + 1):\n",
        "        model.train()\n",
        "\n",
        "        for times, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward and backward propagation\n",
        "            outputs = model(inputs).squeeze(dim=1)\n",
        "            loss = criteria(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        # Train loss and train accuracy\n",
        "        train_current_loss, train_current_accuracy = validation(model, device, train_loader, criteria)\n",
        "\n",
        "        # Early stopping\n",
        "        current_loss, current_accuracy = validation(model, device, valid_loader, criteria)\n",
        "        print('[{}/{} | Train loss: {:.8} | Train accuracy: {:.8} | Test loss: {:.8} | Test accuracy: {:.8}]'.format(epoch, epochs, train_current_loss, train_current_accuracy, current_loss, current_accuracy))\n",
        "        \n",
        "        train_loss_track.append(train_current_loss)\n",
        "        train_accuracy_track.append(train_current_accuracy)\n",
        "        test_loss_track.append(current_loss)\n",
        "        test_accuracy_track.append(current_accuracy)\n",
        "        \n",
        "        if current_loss > last_loss:\n",
        "            trigger_times += 1\n",
        "            print('Trigger times: {}/{}'.format(trigger_times, patience))\n",
        "\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!\\nStart to test process.')\n",
        "                return model\n",
        "\n",
        "        else:\n",
        "            print('Trigger times: 0/{}'.format(patience))\n",
        "            trigger_times = 0\n",
        "\n",
        "        last_loss = current_loss\n",
        "        \n",
        "        if trigger_times == 0:\n",
        "            print('New checkpoint...')\n",
        "            checkpoint(epoch, model, optimizer, criteria, save_as=save_as)\n",
        "\n",
        "    return model, (train_loss_track, train_accuracy_track), (test_loss_track, test_accuracy_track)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sZnDhkhlwyiV",
        "outputId": "d5c2646c-1dff-41af-f336-44eda69a44f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready for new training process... =)\n"
          ]
        }
      ],
      "source": [
        "model = Net(input_features=X_tensor.shape[1])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criteria = nn.BCEWithLogitsLoss()\n",
        "resume = 1\n",
        "v0_path = Path('../Output/NetV0.pth')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "recover = False\n",
        "\n",
        "if v0_path.exists() and recover:\n",
        "    print('Recovering old training process...')\n",
        "    checkpoint = torch.load(v0_path)\n",
        "    resume = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    criteria = checkpoint['criteria']\n",
        "else:\n",
        "    print('Ready for new training process... =)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iekQga58wybC"
      },
      "outputs": [],
      "source": [
        "wanna_train = False\n",
        "if wanna_train:\n",
        "    trained_model, train_stats, test_stats = train(device, model, epochs, optimizer, criteria, train_loader, test_loader, resume=resume, save_as=v0_path)\n",
        "else:\n",
        "    print('Not training this model anymore...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j44nOD2HwyYZ",
        "outputId": "2e66b019-f2be-4bb8-fc0f-2fcd6a7f530f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying last checkpoint of model NetV0 state to trained folder\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WindowsPath('../Trained/NetV0.pth')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "v0_path_trained = Path('../Trained/NetV0.pth')\n",
        "if v0_path.exists():\n",
        "    print('Copying last checkpoint of model {0} state to trained folder'.format('NetV0'))\n",
        "    shutil.copy(v0_path, v0_path_trained)\n",
        "else:\n",
        "    print('Model {0} is not created yeat'.format('NetV0'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni9s7Ng5Pepn",
        "outputId": "38bd6f66-89f9-4235-c678-2f3a9281b840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (main): Sequential(\n",
              "    (0): Linear(in_features=30, out_features=64, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): Tanh()\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): Tanh()\n",
              "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (7): Tanh()\n",
              "    (8): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (9): Tanh()\n",
              "    (10): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (11): Tanh()\n",
              "    (12): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (13): Tanh()\n",
              "    (14): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (15): Tanh()\n",
              "    (16): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (17): Tanh()\n",
              "    (18): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (19): Tanh()\n",
              "    (20): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (21): Tanh()\n",
              "    (22): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (90000, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>209540</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182173</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>195991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>489479</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  target\n",
              "0  209540       0\n",
              "1  182173       0\n",
              "2  195991       1\n",
              "3   43111       0\n",
              "4  489479       1"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v0_path_trained = Path('../Trained/NetV0.pth')\n",
        "v0_state = torch.load(v0_path_trained)\n",
        "v0_state_dict = v0_state['model_state_dict']\n",
        "v0_model = Net()\n",
        "v0_model.load_state_dict(v0_state_dict)\n",
        "\n",
        "validate_path = Path('/content/drive/MyDrive/validate.csv') if IN_COLAB else Path('../Data/validate.csv')\n",
        "validate_df = pd.read_csv(validate_path)\n",
        "X_val = validate_df.drop(['id', 'f_27'], axis=1)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_val_tensor = torch.from_numpy(X_val)\n",
        "X_val_tensor = X_val_tensor.type(torch.float)\n",
        "X_val_tensor = X_val_tensor.to(device)\n",
        "\n",
        "v0_model = v0_model.to(device)\n",
        "v0_model.eval()\n",
        "with torch.inference_mode():\n",
        "    outputs = v0_model(X_val_tensor)\n",
        "    y_pred = torch.round(torch.sigmoid(outputs))\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    \n",
        "submision_df = pd.DataFrame({\n",
        "    'id': validate_df['id'],\n",
        "    'target': y_pred.flatten()\n",
        "})\n",
        "\n",
        "submision_df = submision_df.astype('int')\n",
        "\n",
        "submit_path_model_v0 = Path('../Submit/V0.csv')\n",
        "submision_df.to_csv(submit_path_model_v0, index=False)\n",
        "submision_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TijG7taePepn"
      },
      "source": [
        "## Second approch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE6FG4TJPepn"
      },
      "source": [
        "### One Hot encode f_27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5wNF8BAPepn"
      },
      "source": [
        "This is not the way to go because the dataframe increases a lot..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nq3_X8EPepo",
        "outputId": "8a3d3bd9-cd57-4a3a-bdac-df9e784f9c8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((810000, 31), (810000,))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = df.drop(['target', 'id'], axis=1, errors='ignore'), df['target']\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB7q6tE1Pepo",
        "outputId": "b5ab94f2-9415-4e31-c348-876e9c383138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(678113, 810000)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f_27 = X['f_27']\n",
        "f_27.nunique(), len(f_27)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impossible to handle this amount of data"
      ],
      "metadata": {
        "id": "oIKVtsDwrfS0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2QvtZjRPepo",
        "outputId": "c8e578c8-b09c-4241-ccf3-b7be01c065a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((810000, 678112), scipy.sparse._csr.csr_matrix)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "X['f_27'] = X['f_27'].astype('category')\n",
        "drop_enc = OneHotEncoder(drop='first')\n",
        "sparse = drop_enc.fit_transform(X[['f_27']])\n",
        "sparse.shape, type(sparse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk4hkR-pPepo"
      },
      "source": [
        "Dimentionally reduction the one hot encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apdHGWFsPepo",
        "outputId": "67b82de0-b21e-49bc-9f01-f2c2f85fe7b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TruncatedSVD(n_components=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=10)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "TruncatedSVD(n_components=10)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.46741814e-05 1.32668698e-05 1.17623774e-05 1.17496912e-05\n",
            " 1.03026316e-05 1.02071320e-05 9.98196498e-06 9.45805114e-06\n",
            " 9.19224881e-06 8.83016400e-06]\n",
            "0.00010942531230727259\n",
            "[3.43478639 3.25197463 3.0571312  3.04839654 2.85091836 2.83100822\n",
            " 2.79509639 2.71544367 2.68575579 2.63845535]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "pca = TruncatedSVD(n_components=10)\n",
        "pca.fit(sparse)\n",
        "\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.explained_variance_ratio_.sum())\n",
        "\n",
        "print(pca.singular_values_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llqmbaOrPepp"
      },
      "source": [
        "### Clusterization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried several unsupervised clusterization but none of them performed good or even support sparse matrix. Here I show you the KMeans approch"
      ],
      "metadata": {
        "id": "Y9_ua3VNrxNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-z7BwvHPepp",
        "outputId": "c45fe6b1-922b-48dc-95fd-3a3d651fe55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of elements asigned to each cluster: [810000]\n",
            "Number of elements asigned to each cluster: [809996      4]\n",
            "Number of elements asigned to each cluster: [809994      4      2]\n",
            "Number of elements asigned to each cluster: [809993      4      2      1]\n",
            "Number of elements asigned to each cluster: [809990      4      2      1      3]\n",
            "Number of elements asigned to each cluster: [809988      4      2      1      3      2]\n",
            "Number of elements asigned to each cluster: [809984      4      2      1      3      2      4]\n",
            "Number of elements asigned to each cluster: [809980      4      2      3      2      4      3      2]\n",
            "Number of elements asigned to each cluster: [809979      4      2      3      2      4      3      2      1]\n",
            "Number of elements asigned to each cluster: [809978      4      2      3      2      4      3      2      1      1]\n",
            "\n",
            "True number of documents in each category according to the class labels: [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "for c in range(1, 11):\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=c,\n",
        "        max_iter=300,\n",
        "        n_init='auto',\n",
        "        random_state=42,\n",
        "    ).fit(sparse)\n",
        "    cluster_ids, cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n",
        "    print(f\"Number of elements asigned to each cluster: {cluster_sizes}\")\n",
        "print()\n",
        "print(\n",
        "    \"True number of documents in each category according to the class labels: \"\n",
        "    f\"{cluster_ids}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uiIEJXEPepp"
      },
      "source": [
        "## Smart encoding f_27"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I notice that it was kinda impossible to encode the f_27 with the previous techniques I tought to transform this feature into the number of occurrences that a letter of the code appear and encode each char position into ASCCII and remark which code appear in each position."
      ],
      "metadata": {
        "id": "ql3wuAb0sJHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TKV_DmFPepp",
        "outputId": "ba4c1015-3875-4d3b-9fb0-983d0a13885b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 10\n"
          ]
        }
      ],
      "source": [
        "df['f_27'] = df['f_27'].str.upper()\n",
        "df['length'] = df['f_27'].str.len()\n",
        "print(df['length'].min(), df['length'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in2Y0OF0Pepq",
        "outputId": "0bda536c-d0d9-448d-d061-1e54d5175449"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((810000, 32), (810000,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X, y = df.drop(['target', 'id'], axis=1, errors='ignore'), df['target']\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "FgO7jqYTPepq",
        "outputId": "ae91bd99-9b42-442d-a89b-09cb19e334c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (68) exceeds max_columns (50). Falling back to pandas display.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       f_00      f_01      f_02      f_03      f_04      f_05      f_06  f_07  \\\n",
              "0  0.315471 -0.183690  0.664383 -1.186794  0.665098  0.946208  0.729857     0   \n",
              "1 -1.286392  1.780592  0.576698 -2.690658  1.321997 -0.675894  0.371070     3   \n",
              "2 -0.290303 -0.485907  0.808350 -0.156288  1.083632 -1.129914  0.767396     3   \n",
              "3  1.243590  0.035112 -1.013236  0.854267  0.019192  0.597892 -2.020416     2   \n",
              "4  0.702716  0.817044 -0.064907 -1.045483  0.718374  0.164451 -0.936620     1   \n",
              "\n",
              "   f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18      f_19  \\\n",
              "0     4     1     3     1     2     4     1     5     2     0     1 -3.690715   \n",
              "1     0     3     3     5     3     2     0     1     6     0     1  0.664517   \n",
              "2     1     3     2     3     4     1     1     1     0     2     6 -0.494988   \n",
              "3     0     4     5     0     5     1     0     3     1     1     3 -3.066427   \n",
              "4     2     2     2     2     5     0     3     1     1     2     4 -1.899984   \n",
              "\n",
              "       f_20      f_21      f_22      f_23      f_24      f_25      f_26  \\\n",
              "0 -0.628005 -2.832295 -1.409039  3.645067  0.233039 -3.754846 -1.061733   \n",
              "1 -2.871912  3.826628  3.087653  0.494209  3.210875 -0.666457  0.123854   \n",
              "2 -0.946303  2.333223  2.084169 -4.782668 -1.671375  2.774382  2.273130   \n",
              "3 -2.430158 -0.185332 -0.701691 -2.769142 -6.534231 -0.557677 -0.429972   \n",
              "4  1.427460 -4.992610  1.154162 -1.931443  2.325042  2.143811 -1.039599   \n",
              "\n",
              "         f_27        f_28  f_29  f_30  length  A  B  C  D  E  F  G  H  I  J  \\\n",
              "0  BDBBCACIBB   20.308715     1     0      10  1  5  2  1  0  0  0  0  1  0   \n",
              "1  ACBDCBCADA -449.291063     1     0      10  3  2  3  2  0  0  0  0  0  0   \n",
              "2  AABBABCLAF  -86.206118     0     1      10  4  3  1  0  0  1  0  0  0  0   \n",
              "3  ADBBABEEBA  -30.157403     0     2      10  3  4  0  1  2  0  0  0  0  0   \n",
              "4  ABBBBBCMBB  296.484562     0     2      10  1  7  1  0  0  0  0  0  0  0   \n",
              "\n",
              "   K  L  M  N  O  P  Q  R  S  T  U  V  W  X  Y  Z  pos_0  pos_1  pos_2  pos_3  \\\n",
              "0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0      1      3      1      1   \n",
              "1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0      0      2      1      3   \n",
              "2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0      0      0      1      1   \n",
              "3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0      0      3      1      1   \n",
              "4  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0      0      1      1      1   \n",
              "\n",
              "   pos_4  pos_5  pos_6  pos_7  pos_8  pos_9  \n",
              "0      2      0      2      8      1      1  \n",
              "1      2      1      2      0      3      0  \n",
              "2      0      1      2     11      0      5  \n",
              "3      0      1      4      4      1      0  \n",
              "4      1      1      2     12      1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6db22645-e589-48ef-b063-ac5e151266af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_27</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "      <th>length</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>O</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>pos_0</th>\n",
              "      <th>pos_1</th>\n",
              "      <th>pos_2</th>\n",
              "      <th>pos_3</th>\n",
              "      <th>pos_4</th>\n",
              "      <th>pos_5</th>\n",
              "      <th>pos_6</th>\n",
              "      <th>pos_7</th>\n",
              "      <th>pos_8</th>\n",
              "      <th>pos_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.315471</td>\n",
              "      <td>-0.183690</td>\n",
              "      <td>0.664383</td>\n",
              "      <td>-1.186794</td>\n",
              "      <td>0.665098</td>\n",
              "      <td>0.946208</td>\n",
              "      <td>0.729857</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.690715</td>\n",
              "      <td>-0.628005</td>\n",
              "      <td>-2.832295</td>\n",
              "      <td>-1.409039</td>\n",
              "      <td>3.645067</td>\n",
              "      <td>0.233039</td>\n",
              "      <td>-3.754846</td>\n",
              "      <td>-1.061733</td>\n",
              "      <td>BDBBCACIBB</td>\n",
              "      <td>20.308715</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.286392</td>\n",
              "      <td>1.780592</td>\n",
              "      <td>0.576698</td>\n",
              "      <td>-2.690658</td>\n",
              "      <td>1.321997</td>\n",
              "      <td>-0.675894</td>\n",
              "      <td>0.371070</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.664517</td>\n",
              "      <td>-2.871912</td>\n",
              "      <td>3.826628</td>\n",
              "      <td>3.087653</td>\n",
              "      <td>0.494209</td>\n",
              "      <td>3.210875</td>\n",
              "      <td>-0.666457</td>\n",
              "      <td>0.123854</td>\n",
              "      <td>ACBDCBCADA</td>\n",
              "      <td>-449.291063</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.290303</td>\n",
              "      <td>-0.485907</td>\n",
              "      <td>0.808350</td>\n",
              "      <td>-0.156288</td>\n",
              "      <td>1.083632</td>\n",
              "      <td>-1.129914</td>\n",
              "      <td>0.767396</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.494988</td>\n",
              "      <td>-0.946303</td>\n",
              "      <td>2.333223</td>\n",
              "      <td>2.084169</td>\n",
              "      <td>-4.782668</td>\n",
              "      <td>-1.671375</td>\n",
              "      <td>2.774382</td>\n",
              "      <td>2.273130</td>\n",
              "      <td>AABBABCLAF</td>\n",
              "      <td>-86.206118</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.243590</td>\n",
              "      <td>0.035112</td>\n",
              "      <td>-1.013236</td>\n",
              "      <td>0.854267</td>\n",
              "      <td>0.019192</td>\n",
              "      <td>0.597892</td>\n",
              "      <td>-2.020416</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-3.066427</td>\n",
              "      <td>-2.430158</td>\n",
              "      <td>-0.185332</td>\n",
              "      <td>-0.701691</td>\n",
              "      <td>-2.769142</td>\n",
              "      <td>-6.534231</td>\n",
              "      <td>-0.557677</td>\n",
              "      <td>-0.429972</td>\n",
              "      <td>ADBBABEEBA</td>\n",
              "      <td>-30.157403</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.702716</td>\n",
              "      <td>0.817044</td>\n",
              "      <td>-0.064907</td>\n",
              "      <td>-1.045483</td>\n",
              "      <td>0.718374</td>\n",
              "      <td>0.164451</td>\n",
              "      <td>-0.936620</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.899984</td>\n",
              "      <td>1.427460</td>\n",
              "      <td>-4.992610</td>\n",
              "      <td>1.154162</td>\n",
              "      <td>-1.931443</td>\n",
              "      <td>2.325042</td>\n",
              "      <td>2.143811</td>\n",
              "      <td>-1.039599</td>\n",
              "      <td>ABBBBBCMBB</td>\n",
              "      <td>296.484562</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6db22645-e589-48ef-b063-ac5e151266af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6db22645-e589-48ef-b063-ac5e151266af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6db22645-e589-48ef-b063-ac5e151266af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Counts the number of times a letter appear in the code\n",
        "def add_letters_count(data):\n",
        "    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "    for char in letters:\n",
        "        data[char] = data['f_27'].str.count(char)\n",
        "    return data\n",
        "\n",
        "# For each of the 10 position of the letter code I assign which code letter was assigned to it\n",
        "def add_letter_position(data):\n",
        "    for i in range(10):\n",
        "        data['pos_' + str(i)] = (data['f_27'].str[i]).apply(lambda x: ord(x)) - 65\n",
        "    return data\n",
        "\n",
        "X = add_letters_count(X)\n",
        "X = add_letter_position(X)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "82iY4qFAPepq",
        "outputId": "82596049-2cf2-430e-8120-76250d2f7b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (66) exceeds max_columns (50). Falling back to pandas display.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       f_00      f_01      f_02      f_03      f_04      f_05      f_06  f_07  \\\n",
              "0  0.315471 -0.183690  0.664383 -1.186794  0.665098  0.946208  0.729857     0   \n",
              "1 -1.286392  1.780592  0.576698 -2.690658  1.321997 -0.675894  0.371070     3   \n",
              "2 -0.290303 -0.485907  0.808350 -0.156288  1.083632 -1.129914  0.767396     3   \n",
              "3  1.243590  0.035112 -1.013236  0.854267  0.019192  0.597892 -2.020416     2   \n",
              "4  0.702716  0.817044 -0.064907 -1.045483  0.718374  0.164451 -0.936620     1   \n",
              "\n",
              "   f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18      f_19  \\\n",
              "0     4     1     3     1     2     4     1     5     2     0     1 -3.690715   \n",
              "1     0     3     3     5     3     2     0     1     6     0     1  0.664517   \n",
              "2     1     3     2     3     4     1     1     1     0     2     6 -0.494988   \n",
              "3     0     4     5     0     5     1     0     3     1     1     3 -3.066427   \n",
              "4     2     2     2     2     5     0     3     1     1     2     4 -1.899984   \n",
              "\n",
              "       f_20      f_21      f_22      f_23      f_24      f_25      f_26  \\\n",
              "0 -0.628005 -2.832295 -1.409039  3.645067  0.233039 -3.754846 -1.061733   \n",
              "1 -2.871912  3.826628  3.087653  0.494209  3.210875 -0.666457  0.123854   \n",
              "2 -0.946303  2.333223  2.084169 -4.782668 -1.671375  2.774382  2.273130   \n",
              "3 -2.430158 -0.185332 -0.701691 -2.769142 -6.534231 -0.557677 -0.429972   \n",
              "4  1.427460 -4.992610  1.154162 -1.931443  2.325042  2.143811 -1.039599   \n",
              "\n",
              "         f_28  f_29  f_30  A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  \\\n",
              "0   20.308715     1     0  1  5  2  1  0  0  0  0  1  0  0  0  0  0  0  0  0   \n",
              "1 -449.291063     1     0  3  2  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0   \n",
              "2  -86.206118     0     1  4  3  1  0  0  1  0  0  0  0  0  1  0  0  0  0  0   \n",
              "3  -30.157403     0     2  3  4  0  1  2  0  0  0  0  0  0  0  0  0  0  0  0   \n",
              "4  296.484562     0     2  1  7  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0   \n",
              "\n",
              "   R  S  T  U  V  W  X  Y  Z  pos_0  pos_1  pos_2  pos_3  pos_4  pos_5  pos_6  \\\n",
              "0  0  0  0  0  0  0  0  0  0      1      3      1      1      2      0      2   \n",
              "1  0  0  0  0  0  0  0  0  0      0      2      1      3      2      1      2   \n",
              "2  0  0  0  0  0  0  0  0  0      0      0      1      1      0      1      2   \n",
              "3  0  0  0  0  0  0  0  0  0      0      3      1      1      0      1      4   \n",
              "4  0  0  0  0  0  0  0  0  0      0      1      1      1      1      1      2   \n",
              "\n",
              "   pos_7  pos_8  pos_9  \n",
              "0      8      1      1  \n",
              "1      0      3      0  \n",
              "2     11      0      5  \n",
              "3      4      1      0  \n",
              "4     12      1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cf155ae-1c3e-4818-895e-b2505de39774\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>O</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>pos_0</th>\n",
              "      <th>pos_1</th>\n",
              "      <th>pos_2</th>\n",
              "      <th>pos_3</th>\n",
              "      <th>pos_4</th>\n",
              "      <th>pos_5</th>\n",
              "      <th>pos_6</th>\n",
              "      <th>pos_7</th>\n",
              "      <th>pos_8</th>\n",
              "      <th>pos_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.315471</td>\n",
              "      <td>-0.183690</td>\n",
              "      <td>0.664383</td>\n",
              "      <td>-1.186794</td>\n",
              "      <td>0.665098</td>\n",
              "      <td>0.946208</td>\n",
              "      <td>0.729857</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.690715</td>\n",
              "      <td>-0.628005</td>\n",
              "      <td>-2.832295</td>\n",
              "      <td>-1.409039</td>\n",
              "      <td>3.645067</td>\n",
              "      <td>0.233039</td>\n",
              "      <td>-3.754846</td>\n",
              "      <td>-1.061733</td>\n",
              "      <td>20.308715</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.286392</td>\n",
              "      <td>1.780592</td>\n",
              "      <td>0.576698</td>\n",
              "      <td>-2.690658</td>\n",
              "      <td>1.321997</td>\n",
              "      <td>-0.675894</td>\n",
              "      <td>0.371070</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.664517</td>\n",
              "      <td>-2.871912</td>\n",
              "      <td>3.826628</td>\n",
              "      <td>3.087653</td>\n",
              "      <td>0.494209</td>\n",
              "      <td>3.210875</td>\n",
              "      <td>-0.666457</td>\n",
              "      <td>0.123854</td>\n",
              "      <td>-449.291063</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.290303</td>\n",
              "      <td>-0.485907</td>\n",
              "      <td>0.808350</td>\n",
              "      <td>-0.156288</td>\n",
              "      <td>1.083632</td>\n",
              "      <td>-1.129914</td>\n",
              "      <td>0.767396</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.494988</td>\n",
              "      <td>-0.946303</td>\n",
              "      <td>2.333223</td>\n",
              "      <td>2.084169</td>\n",
              "      <td>-4.782668</td>\n",
              "      <td>-1.671375</td>\n",
              "      <td>2.774382</td>\n",
              "      <td>2.273130</td>\n",
              "      <td>-86.206118</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.243590</td>\n",
              "      <td>0.035112</td>\n",
              "      <td>-1.013236</td>\n",
              "      <td>0.854267</td>\n",
              "      <td>0.019192</td>\n",
              "      <td>0.597892</td>\n",
              "      <td>-2.020416</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-3.066427</td>\n",
              "      <td>-2.430158</td>\n",
              "      <td>-0.185332</td>\n",
              "      <td>-0.701691</td>\n",
              "      <td>-2.769142</td>\n",
              "      <td>-6.534231</td>\n",
              "      <td>-0.557677</td>\n",
              "      <td>-0.429972</td>\n",
              "      <td>-30.157403</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.702716</td>\n",
              "      <td>0.817044</td>\n",
              "      <td>-0.064907</td>\n",
              "      <td>-1.045483</td>\n",
              "      <td>0.718374</td>\n",
              "      <td>0.164451</td>\n",
              "      <td>-0.936620</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.899984</td>\n",
              "      <td>1.427460</td>\n",
              "      <td>-4.992610</td>\n",
              "      <td>1.154162</td>\n",
              "      <td>-1.931443</td>\n",
              "      <td>2.325042</td>\n",
              "      <td>2.143811</td>\n",
              "      <td>-1.039599</td>\n",
              "      <td>296.484562</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cf155ae-1c3e-4818-895e-b2505de39774')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cf155ae-1c3e-4818-895e-b2505de39774 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cf155ae-1c3e-4818-895e-b2505de39774');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Drops unneded features\n",
        "X = X.drop(['f_27', 'length'], axis=1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "YjKTv1ThPepq",
        "outputId": "0768866f-b249-4b2a-ab0e-0f16d65f428b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (66) exceeds max_columns (50). Falling back to pandas display.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
              "0  0.315508 -0.185365  0.663485 -1.184789  0.665919  0.945566  0.731168   \n",
              "1 -1.288412  1.780094  0.575879 -2.688532  1.322818 -0.676539  0.372214   \n",
              "2 -0.291044 -0.487763  0.807325 -0.154365  1.084453 -1.130560  0.768724   \n",
              "3  1.244818  0.033569 -1.012640  0.856109  0.020013  0.597249 -2.020385   \n",
              "4  0.703249  0.815969 -0.065154 -1.043488  0.719195  0.163808 -0.936084   \n",
              "\n",
              "       f_07      f_08      f_09      f_10      f_11      f_12      f_13  \\\n",
              "0 -1.226551  1.220861 -0.832130  0.499632 -0.522922 -0.477867  1.145009   \n",
              "1  0.584225 -1.293760  0.389265  0.499632  2.078555  0.089454 -0.155626   \n",
              "2  0.584225 -0.665105  0.389265 -0.108080  0.777817  0.656775 -0.805943   \n",
              "3 -0.019367 -1.293760  0.999962  1.715054 -1.173291  1.224096 -0.805943   \n",
              "4 -0.622959 -0.036450 -0.221433 -0.108080  0.127447  1.224096 -1.456260   \n",
              "\n",
              "       f_14      f_15      f_16      f_17      f_18      f_19      f_20  \\\n",
              "0 -0.379035  1.847503 -0.061861 -1.265929 -0.680877 -1.727077 -0.187118   \n",
              "1 -1.114439 -0.701972  2.502279 -1.265929 -0.680877  0.154349 -1.121819   \n",
              "2 -0.379035 -0.701972 -1.343932  0.096928  2.512803 -0.346548 -0.319705   \n",
              "3 -1.114439  0.572765 -0.702897 -0.584500  0.596595 -1.457389 -0.937806   \n",
              "4  1.091772 -0.701972 -0.702897  0.096928  1.235331 -0.953495  0.669086   \n",
              "\n",
              "       f_21      f_22      f_23      f_24      f_25      f_26      f_28  \\\n",
              "0 -1.076850 -0.571024  1.635696  0.241191 -1.626472 -0.572666  0.086945   \n",
              "1  1.603352  1.263992  0.351786  1.488661 -0.348562 -0.093987 -1.880083   \n",
              "2  1.002260  0.854489 -1.798432 -0.556603  1.075183  0.773779 -0.359217   \n",
              "3 -0.011453 -0.282369 -0.977962 -2.593742 -0.303552 -0.317593 -0.124444   \n",
              "4 -1.946372  0.474970 -0.636617  1.117569  0.814266 -0.563729  1.243772   \n",
              "\n",
              "       f_29      f_30         A         B         C         D         E  \\\n",
              "0  1.376157 -1.224123 -1.083869  1.234584  0.490294 -0.031583 -0.814115   \n",
              "1  1.376157 -1.224123  0.399822 -0.874097  1.430813  1.044383 -0.814115   \n",
              "2 -0.726661 -0.002898  1.141668 -0.171203 -0.450225 -1.107548 -0.814115   \n",
              "3 -0.726661  1.218327  0.399822  0.531690 -1.390745 -0.031583  1.909363   \n",
              "4 -0.726661  1.218327 -1.083869  2.640371 -0.450225 -1.107548 -0.814115   \n",
              "\n",
              "          F         G         H         I         J         K         L  \\\n",
              "0 -0.576194 -0.411349 -0.311859  3.705131 -0.241643 -0.234669 -0.232101   \n",
              "1 -0.576194 -0.411349 -0.311859 -0.262396 -0.241643 -0.234669 -0.232101   \n",
              "2  1.252204 -0.411349 -0.311859 -0.262396 -0.241643 -0.234669  4.303646   \n",
              "3 -0.576194 -0.411349 -0.311859 -0.262396 -0.241643 -0.234669 -0.232101   \n",
              "4 -0.576194 -0.411349 -0.311859 -0.262396 -0.241643 -0.234669 -0.232101   \n",
              "\n",
              "          M         N         O         P         Q         R      S  \\\n",
              "0 -0.232078 -0.231841 -0.230273 -0.229907 -0.228613 -0.225631 -0.221   \n",
              "1 -0.232078 -0.231841 -0.230273 -0.229907 -0.228613 -0.225631 -0.221   \n",
              "2 -0.232078 -0.231841 -0.230273 -0.229907 -0.228613 -0.225631 -0.221   \n",
              "3 -0.232078 -0.231841 -0.230273 -0.229907 -0.228613 -0.225631 -0.221   \n",
              "4  4.307805 -0.231841 -0.230273 -0.229907 -0.228613 -0.225631 -0.221   \n",
              "\n",
              "          T    U    V    W    X    Y    Z     pos_0     pos_1     pos_2  \\\n",
              "0 -0.213519  0.0  0.0  0.0  0.0  0.0  0.0  1.003054  0.689322  0.703296   \n",
              "1 -0.213519  0.0  0.0  0.0  0.0  0.0  0.0 -0.996955  0.022464  0.703296   \n",
              "2 -0.213519  0.0  0.0  0.0  0.0  0.0  0.0 -0.996955 -1.311252  0.703296   \n",
              "3 -0.213519  0.0  0.0  0.0  0.0  0.0  0.0 -0.996955  0.689322  0.703296   \n",
              "4 -0.213519  0.0  0.0  0.0  0.0  0.0  0.0 -0.996955 -0.644394  0.703296   \n",
              "\n",
              "      pos_3     pos_4     pos_5     pos_6     pos_7     pos_8     pos_9  \n",
              "0 -0.620112  0.472564 -0.937307 -0.228211 -0.240395 -0.639293 -0.777127  \n",
              "1  0.632781  0.472564  1.066887 -0.228211 -1.642581  0.610917 -1.382270  \n",
              "2 -0.620112 -1.068348  1.066887 -0.228211  0.285425 -1.264398  1.643445  \n",
              "3 -0.620112 -1.068348  1.066887  0.979742 -0.941488 -0.639293 -1.382270  \n",
              "4 -0.620112 -0.297892  1.066887 -0.228211  0.460699 -0.639293 -0.777127  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bf6a9be-fe97-4aa0-bd7c-b937786148b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_00</th>\n",
              "      <th>f_01</th>\n",
              "      <th>f_02</th>\n",
              "      <th>f_03</th>\n",
              "      <th>f_04</th>\n",
              "      <th>f_05</th>\n",
              "      <th>f_06</th>\n",
              "      <th>f_07</th>\n",
              "      <th>f_08</th>\n",
              "      <th>f_09</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>O</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>pos_0</th>\n",
              "      <th>pos_1</th>\n",
              "      <th>pos_2</th>\n",
              "      <th>pos_3</th>\n",
              "      <th>pos_4</th>\n",
              "      <th>pos_5</th>\n",
              "      <th>pos_6</th>\n",
              "      <th>pos_7</th>\n",
              "      <th>pos_8</th>\n",
              "      <th>pos_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.315508</td>\n",
              "      <td>-0.185365</td>\n",
              "      <td>0.663485</td>\n",
              "      <td>-1.184789</td>\n",
              "      <td>0.665919</td>\n",
              "      <td>0.945566</td>\n",
              "      <td>0.731168</td>\n",
              "      <td>-1.226551</td>\n",
              "      <td>1.220861</td>\n",
              "      <td>-0.832130</td>\n",
              "      <td>0.499632</td>\n",
              "      <td>-0.522922</td>\n",
              "      <td>-0.477867</td>\n",
              "      <td>1.145009</td>\n",
              "      <td>-0.379035</td>\n",
              "      <td>1.847503</td>\n",
              "      <td>-0.061861</td>\n",
              "      <td>-1.265929</td>\n",
              "      <td>-0.680877</td>\n",
              "      <td>-1.727077</td>\n",
              "      <td>-0.187118</td>\n",
              "      <td>-1.076850</td>\n",
              "      <td>-0.571024</td>\n",
              "      <td>1.635696</td>\n",
              "      <td>0.241191</td>\n",
              "      <td>-1.626472</td>\n",
              "      <td>-0.572666</td>\n",
              "      <td>0.086945</td>\n",
              "      <td>1.376157</td>\n",
              "      <td>-1.224123</td>\n",
              "      <td>-1.083869</td>\n",
              "      <td>1.234584</td>\n",
              "      <td>0.490294</td>\n",
              "      <td>-0.031583</td>\n",
              "      <td>-0.814115</td>\n",
              "      <td>-0.576194</td>\n",
              "      <td>-0.411349</td>\n",
              "      <td>-0.311859</td>\n",
              "      <td>3.705131</td>\n",
              "      <td>-0.241643</td>\n",
              "      <td>-0.234669</td>\n",
              "      <td>-0.232101</td>\n",
              "      <td>-0.232078</td>\n",
              "      <td>-0.231841</td>\n",
              "      <td>-0.230273</td>\n",
              "      <td>-0.229907</td>\n",
              "      <td>-0.228613</td>\n",
              "      <td>-0.225631</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.213519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003054</td>\n",
              "      <td>0.689322</td>\n",
              "      <td>0.703296</td>\n",
              "      <td>-0.620112</td>\n",
              "      <td>0.472564</td>\n",
              "      <td>-0.937307</td>\n",
              "      <td>-0.228211</td>\n",
              "      <td>-0.240395</td>\n",
              "      <td>-0.639293</td>\n",
              "      <td>-0.777127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.288412</td>\n",
              "      <td>1.780094</td>\n",
              "      <td>0.575879</td>\n",
              "      <td>-2.688532</td>\n",
              "      <td>1.322818</td>\n",
              "      <td>-0.676539</td>\n",
              "      <td>0.372214</td>\n",
              "      <td>0.584225</td>\n",
              "      <td>-1.293760</td>\n",
              "      <td>0.389265</td>\n",
              "      <td>0.499632</td>\n",
              "      <td>2.078555</td>\n",
              "      <td>0.089454</td>\n",
              "      <td>-0.155626</td>\n",
              "      <td>-1.114439</td>\n",
              "      <td>-0.701972</td>\n",
              "      <td>2.502279</td>\n",
              "      <td>-1.265929</td>\n",
              "      <td>-0.680877</td>\n",
              "      <td>0.154349</td>\n",
              "      <td>-1.121819</td>\n",
              "      <td>1.603352</td>\n",
              "      <td>1.263992</td>\n",
              "      <td>0.351786</td>\n",
              "      <td>1.488661</td>\n",
              "      <td>-0.348562</td>\n",
              "      <td>-0.093987</td>\n",
              "      <td>-1.880083</td>\n",
              "      <td>1.376157</td>\n",
              "      <td>-1.224123</td>\n",
              "      <td>0.399822</td>\n",
              "      <td>-0.874097</td>\n",
              "      <td>1.430813</td>\n",
              "      <td>1.044383</td>\n",
              "      <td>-0.814115</td>\n",
              "      <td>-0.576194</td>\n",
              "      <td>-0.411349</td>\n",
              "      <td>-0.311859</td>\n",
              "      <td>-0.262396</td>\n",
              "      <td>-0.241643</td>\n",
              "      <td>-0.234669</td>\n",
              "      <td>-0.232101</td>\n",
              "      <td>-0.232078</td>\n",
              "      <td>-0.231841</td>\n",
              "      <td>-0.230273</td>\n",
              "      <td>-0.229907</td>\n",
              "      <td>-0.228613</td>\n",
              "      <td>-0.225631</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.213519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.996955</td>\n",
              "      <td>0.022464</td>\n",
              "      <td>0.703296</td>\n",
              "      <td>0.632781</td>\n",
              "      <td>0.472564</td>\n",
              "      <td>1.066887</td>\n",
              "      <td>-0.228211</td>\n",
              "      <td>-1.642581</td>\n",
              "      <td>0.610917</td>\n",
              "      <td>-1.382270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.291044</td>\n",
              "      <td>-0.487763</td>\n",
              "      <td>0.807325</td>\n",
              "      <td>-0.154365</td>\n",
              "      <td>1.084453</td>\n",
              "      <td>-1.130560</td>\n",
              "      <td>0.768724</td>\n",
              "      <td>0.584225</td>\n",
              "      <td>-0.665105</td>\n",
              "      <td>0.389265</td>\n",
              "      <td>-0.108080</td>\n",
              "      <td>0.777817</td>\n",
              "      <td>0.656775</td>\n",
              "      <td>-0.805943</td>\n",
              "      <td>-0.379035</td>\n",
              "      <td>-0.701972</td>\n",
              "      <td>-1.343932</td>\n",
              "      <td>0.096928</td>\n",
              "      <td>2.512803</td>\n",
              "      <td>-0.346548</td>\n",
              "      <td>-0.319705</td>\n",
              "      <td>1.002260</td>\n",
              "      <td>0.854489</td>\n",
              "      <td>-1.798432</td>\n",
              "      <td>-0.556603</td>\n",
              "      <td>1.075183</td>\n",
              "      <td>0.773779</td>\n",
              "      <td>-0.359217</td>\n",
              "      <td>-0.726661</td>\n",
              "      <td>-0.002898</td>\n",
              "      <td>1.141668</td>\n",
              "      <td>-0.171203</td>\n",
              "      <td>-0.450225</td>\n",
              "      <td>-1.107548</td>\n",
              "      <td>-0.814115</td>\n",
              "      <td>1.252204</td>\n",
              "      <td>-0.411349</td>\n",
              "      <td>-0.311859</td>\n",
              "      <td>-0.262396</td>\n",
              "      <td>-0.241643</td>\n",
              "      <td>-0.234669</td>\n",
              "      <td>4.303646</td>\n",
              "      <td>-0.232078</td>\n",
              "      <td>-0.231841</td>\n",
              "      <td>-0.230273</td>\n",
              "      <td>-0.229907</td>\n",
              "      <td>-0.228613</td>\n",
              "      <td>-0.225631</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.213519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.996955</td>\n",
              "      <td>-1.311252</td>\n",
              "      <td>0.703296</td>\n",
              "      <td>-0.620112</td>\n",
              "      <td>-1.068348</td>\n",
              "      <td>1.066887</td>\n",
              "      <td>-0.228211</td>\n",
              "      <td>0.285425</td>\n",
              "      <td>-1.264398</td>\n",
              "      <td>1.643445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.244818</td>\n",
              "      <td>0.033569</td>\n",
              "      <td>-1.012640</td>\n",
              "      <td>0.856109</td>\n",
              "      <td>0.020013</td>\n",
              "      <td>0.597249</td>\n",
              "      <td>-2.020385</td>\n",
              "      <td>-0.019367</td>\n",
              "      <td>-1.293760</td>\n",
              "      <td>0.999962</td>\n",
              "      <td>1.715054</td>\n",
              "      <td>-1.173291</td>\n",
              "      <td>1.224096</td>\n",
              "      <td>-0.805943</td>\n",
              "      <td>-1.114439</td>\n",
              "      <td>0.572765</td>\n",
              "      <td>-0.702897</td>\n",
              "      <td>-0.584500</td>\n",
              "      <td>0.596595</td>\n",
              "      <td>-1.457389</td>\n",
              "      <td>-0.937806</td>\n",
              "      <td>-0.011453</td>\n",
              "      <td>-0.282369</td>\n",
              "      <td>-0.977962</td>\n",
              "      <td>-2.593742</td>\n",
              "      <td>-0.303552</td>\n",
              "      <td>-0.317593</td>\n",
              "      <td>-0.124444</td>\n",
              "      <td>-0.726661</td>\n",
              "      <td>1.218327</td>\n",
              "      <td>0.399822</td>\n",
              "      <td>0.531690</td>\n",
              "      <td>-1.390745</td>\n",
              "      <td>-0.031583</td>\n",
              "      <td>1.909363</td>\n",
              "      <td>-0.576194</td>\n",
              "      <td>-0.411349</td>\n",
              "      <td>-0.311859</td>\n",
              "      <td>-0.262396</td>\n",
              "      <td>-0.241643</td>\n",
              "      <td>-0.234669</td>\n",
              "      <td>-0.232101</td>\n",
              "      <td>-0.232078</td>\n",
              "      <td>-0.231841</td>\n",
              "      <td>-0.230273</td>\n",
              "      <td>-0.229907</td>\n",
              "      <td>-0.228613</td>\n",
              "      <td>-0.225631</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.213519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.996955</td>\n",
              "      <td>0.689322</td>\n",
              "      <td>0.703296</td>\n",
              "      <td>-0.620112</td>\n",
              "      <td>-1.068348</td>\n",
              "      <td>1.066887</td>\n",
              "      <td>0.979742</td>\n",
              "      <td>-0.941488</td>\n",
              "      <td>-0.639293</td>\n",
              "      <td>-1.382270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.703249</td>\n",
              "      <td>0.815969</td>\n",
              "      <td>-0.065154</td>\n",
              "      <td>-1.043488</td>\n",
              "      <td>0.719195</td>\n",
              "      <td>0.163808</td>\n",
              "      <td>-0.936084</td>\n",
              "      <td>-0.622959</td>\n",
              "      <td>-0.036450</td>\n",
              "      <td>-0.221433</td>\n",
              "      <td>-0.108080</td>\n",
              "      <td>0.127447</td>\n",
              "      <td>1.224096</td>\n",
              "      <td>-1.456260</td>\n",
              "      <td>1.091772</td>\n",
              "      <td>-0.701972</td>\n",
              "      <td>-0.702897</td>\n",
              "      <td>0.096928</td>\n",
              "      <td>1.235331</td>\n",
              "      <td>-0.953495</td>\n",
              "      <td>0.669086</td>\n",
              "      <td>-1.946372</td>\n",
              "      <td>0.474970</td>\n",
              "      <td>-0.636617</td>\n",
              "      <td>1.117569</td>\n",
              "      <td>0.814266</td>\n",
              "      <td>-0.563729</td>\n",
              "      <td>1.243772</td>\n",
              "      <td>-0.726661</td>\n",
              "      <td>1.218327</td>\n",
              "      <td>-1.083869</td>\n",
              "      <td>2.640371</td>\n",
              "      <td>-0.450225</td>\n",
              "      <td>-1.107548</td>\n",
              "      <td>-0.814115</td>\n",
              "      <td>-0.576194</td>\n",
              "      <td>-0.411349</td>\n",
              "      <td>-0.311859</td>\n",
              "      <td>-0.262396</td>\n",
              "      <td>-0.241643</td>\n",
              "      <td>-0.234669</td>\n",
              "      <td>-0.232101</td>\n",
              "      <td>4.307805</td>\n",
              "      <td>-0.231841</td>\n",
              "      <td>-0.230273</td>\n",
              "      <td>-0.229907</td>\n",
              "      <td>-0.228613</td>\n",
              "      <td>-0.225631</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.213519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.996955</td>\n",
              "      <td>-0.644394</td>\n",
              "      <td>0.703296</td>\n",
              "      <td>-0.620112</td>\n",
              "      <td>-0.297892</td>\n",
              "      <td>1.066887</td>\n",
              "      <td>-0.228211</td>\n",
              "      <td>0.460699</td>\n",
              "      <td>-0.639293</td>\n",
              "      <td>-0.777127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bf6a9be-fe97-4aa0-bd7c-b937786148b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bf6a9be-fe97-4aa0-bd7c-b937786148b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bf6a9be-fe97-4aa0-bd7c-b937786148b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncdcszL7Pepr",
        "outputId": "3ed3a764-d106-4782-8280-5e3e27ed8dda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([810000, 66])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Declare the hole dataset\n",
        "X_tensor, y_tensor = torch.from_numpy(X.to_numpy()), torch.from_numpy(y.to_numpy())\n",
        "X_tensor, y_tensor = X_tensor.type(torch.float), y_tensor.type(torch.float)\n",
        "X_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fDII01Oiwx6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943718a3-f170-42f6-da23-4b1486586349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready for new training process... =)\n"
          ]
        }
      ],
      "source": [
        "dataset = CustomDataset(data=X_tensor, labels=y_tensor)\n",
        "\n",
        "train_dataset, test_dataset = datasets(dataset, y, test_size=0.15)\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = Net(input_features=X_tensor.shape[1])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criteria = nn.BCEWithLogitsLoss()\n",
        "resume = 1\n",
        "v1_path = Path('../Output/NetV1.pth')\n",
        "\n",
        "recover = False\n",
        "\n",
        "if v1_path.exists() and recover:\n",
        "    print('Recovering old training process...')\n",
        "    checkpoint = torch.load(v1_path)\n",
        "    resume = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    criteria = checkpoint['criteria']\n",
        "else:\n",
        "    print('Ready for new training process... =)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3psdKfuPepr"
      },
      "outputs": [],
      "source": [
        "wanna_train = False \n",
        "if wanna_train: # Doen't learn with the previous model\n",
        "    trained_model, train_stats, test_stats = train(device, model, epochs, optimizer, criteria, train_loader, test_loader, resume=resume, save_as=v1_path)\n",
        "else:\n",
        "    print('Not training this model anymore...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgRW6cEWPepr",
        "outputId": "b397d8a4-47f6-4905-ac2b-2a606132634e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying last checkpoint of model NetV1 state to trained folder\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "v1_path_trained = Path('../Trained/NetV1.pth')\n",
        "if v1_path.exists():\n",
        "    print('Copying last checkpoint of model {0} state to trained folder'.format('NetV1'))\n",
        "    shutil.copy(v1_path, v1_path_trained)\n",
        "else:\n",
        "    print('Model {0} is not created yeat'.format('NetV1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "IjfeFG6DPeps",
        "outputId": "247661d6-f5ad-4c1c-ab33-d0f505d1bc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (90000, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  target\n",
              "0  209540       0\n",
              "1  182173       0\n",
              "2  195991       1\n",
              "3   43111       0\n",
              "4  489479       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4eed7016-d916-4c8f-9794-5c749aabc805\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>209540</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182173</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>195991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>489479</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eed7016-d916-4c8f-9794-5c749aabc805')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4eed7016-d916-4c8f-9794-5c749aabc805 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4eed7016-d916-4c8f-9794-5c749aabc805');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 209540,\n            'f': \"209540\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 182173,\n            'f': \"182173\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 195991,\n            'f': \"195991\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 43111,\n            'f': \"43111\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 489479,\n            'f': \"489479\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"number\", \"target\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "validate_path = Path('/content/drive/MyDrive/validate.csv') if IN_COLAB else Path('../Data/validate.csv')\n",
        "validate_df = pd.read_csv(validate_path)\n",
        "X_val = validate_df.drop('id', axis=1)\n",
        "X_val = add_letters_count(X_val)\n",
        "X_val = add_letter_position(X_val)\n",
        "\n",
        "X_val = X_val.drop('f_27', axis=1)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_val_tensor = torch.from_numpy(X_val)\n",
        "X_val_tensor = X_val_tensor.type(torch.float)\n",
        "X_val_tensor = X_val_tensor.to(device)\n",
        "\n",
        "v1_path_trained = Path('../Trained/NetV1.pth')\n",
        "v1_state = torch.load(v1_path_trained)\n",
        "v1_state_dict = v1_state['model_state_dict']\n",
        "v1_model = Net(X_val_tensor.shape[1])\n",
        "v1_model.load_state_dict(v1_state_dict)\n",
        "\n",
        "\n",
        "v1_model = v1_model.to(device)\n",
        "v1_model.eval()\n",
        "with torch.inference_mode():\n",
        "    outputs = v1_model(X_val_tensor)\n",
        "    y_pred = torch.round(torch.sigmoid(outputs))\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    print(type(y_pred), y_pred.shape)\n",
        "    \n",
        "submision_df = pd.DataFrame({\n",
        "    'id': validate_df['id'],\n",
        "    'target': y_pred.flatten()\n",
        "})\n",
        "\n",
        "submision_df = submision_df.astype('int')\n",
        "\n",
        "submit_path_model_v1 = Path('../Submit/V1.csv')\n",
        "submision_df.to_csv(submit_path_model_v1, index=False)\n",
        "submision_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Study of the f_27"
      ],
      "metadata": {
        "id": "jBOA193Ls131"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wanna check if each character of the abecedary appear either in the train set and the validation set. I was amazed because letter after T are not pressent, so what I can do is to drop this columns from the training and the test set and maybe improve my model."
      ],
      "metadata": {
        "id": "8Q4t_FRhtDcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = Path('/content/drive/MyDrive/train.csv') if IN_COLAB else Path('../Data/train.csv')\n",
        "train_df = pd.read_csv(train_path)\n",
        "validate_path = Path('/content/drive/MyDrive/validate.csv') if IN_COLAB else Path('../Data/validate.csv')\n",
        "validate_df = pd.read_csv(validate_path)\n",
        "\n",
        "codes = pd.concat([train_df['f_27'], validate_df['f_27']], axis=0)\n",
        "codes = codes.map(lambda code : [c for c in code])\n",
        "codes = codes.explode()\n",
        "codes = codes.value_counts()\n",
        "data = np.array([list(codes.index), codes.values]).T\n",
        "frequencies = pd.DataFrame(data=data, columns = ['letter', 'freq'])\n",
        "frequencies.sort_values('letter')"
      ],
      "metadata": {
        "id": "HtPf1UNAtNzy",
        "outputId": "9bf070ec-3d4d-493b-b4bd-7c44d155f74d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   letter     freq\n",
              "1       A  2214818\n",
              "0       B  2919752\n",
              "2       C  1331088\n",
              "3       D   926075\n",
              "4       E   537776\n",
              "5       F   283771\n",
              "6       G   147484\n",
              "7       H    84653\n",
              "8       I    59478\n",
              "9       J    50043\n",
              "10      K    47008\n",
              "12      L    46099\n",
              "11      M    46104\n",
              "13      N    45943\n",
              "14      O    45442\n",
              "15      P    45277\n",
              "16      Q    44641\n",
              "17      R    43438\n",
              "18      S    41835\n",
              "19      T    39275"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00eef1fd-f8fe-49d7-bf4d-30fd3468418e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>2214818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>2919752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>1331088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>926075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E</td>\n",
              "      <td>537776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>F</td>\n",
              "      <td>283771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>G</td>\n",
              "      <td>147484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>H</td>\n",
              "      <td>84653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I</td>\n",
              "      <td>59478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>J</td>\n",
              "      <td>50043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>K</td>\n",
              "      <td>47008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>L</td>\n",
              "      <td>46099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>M</td>\n",
              "      <td>46104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>N</td>\n",
              "      <td>45943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>O</td>\n",
              "      <td>45442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>P</td>\n",
              "      <td>45277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Q</td>\n",
              "      <td>44641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>R</td>\n",
              "      <td>43438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>S</td>\n",
              "      <td>41835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>T</td>\n",
              "      <td>39275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00eef1fd-f8fe-49d7-bf4d-30fd3468418e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00eef1fd-f8fe-49d7-bf4d-30fd3468418e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00eef1fd-f8fe-49d7-bf4d-30fd3468418e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 1,\n            'f': \"1\",\n        },\n\"A\",\n\"2214818\"],\n [{\n            'v': 0,\n            'f': \"0\",\n        },\n\"B\",\n\"2919752\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"C\",\n\"1331088\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"D\",\n\"926075\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"E\",\n\"537776\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"F\",\n\"283771\"],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"G\",\n\"147484\"],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"H\",\n\"84653\"],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"I\",\n\"59478\"],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"J\",\n\"50043\"],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"K\",\n\"47008\"],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n\"L\",\n\"46099\"],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"M\",\n\"46104\"],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n\"N\",\n\"45943\"],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n\"O\",\n\"45442\"],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n\"P\",\n\"45277\"],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n\"Q\",\n\"44641\"],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n\"R\",\n\"43438\"],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"S\",\n\"41835\"],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"T\",\n\"39275\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"letter\"], [\"string\", \"freq\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codes.index"
      ],
      "metadata": {
        "id": "40dDa5SNwP5I",
        "outputId": "5668200f-7c15-4d8f-e0db-7642c3ef5199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['B', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'M', 'L', 'N',\n",
              "       'O', 'P', 'Q', 'R', 'S', 'T'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([list(codes.index), codes.values]).T.shape"
      ],
      "metadata": {
        "id": "lN7n3gCOwcGk",
        "outputId": "3e2e085b-3a2d-4e0a-c917-e8883f6ea48b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codes.values"
      ],
      "metadata": {
        "id": "IW-El2-DwMdj",
        "outputId": "db7fd86f-3128-41de-f9cc-5edfb711da6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2919752, 2214818, 1331088,  926075,  537776,  283771,  147484,\n",
              "         84653,   59478,   50043,   47008,   46104,   46099,   45943,\n",
              "         45442,   45277,   44641,   43438,   41835,   39275])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x for x in 'hola']"
      ],
      "metadata": {
        "id": "ABoJ-K2guCM5",
        "outputId": "7ff9b66e-52b8-4609-82ea-9f2ece88a003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h', 'o', 'l', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jK1jW-XLtPPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhQenQkttPNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5I-LzlGtPK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsTbxkKdtPIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gH0yZsTttPGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hYp0dBa1tPD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyo038SitPBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FpGk4ag0tO-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ya5LTGletO8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvnQvQdXtO58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrnijA4wtO3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDDmY59NtOzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "co9EYZJKtOxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJGKF8lttOrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Tgrt-b0tOcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYC9P-upPeps",
        "outputId": "0a64c56b-a904-43c9-a5ee-15fed6c26b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready for new training process... =)\n"
          ]
        }
      ],
      "source": [
        "dataset = CustomDataset(data=X_tensor, labels=y_tensor)\n",
        "\n",
        "train_dataset, test_dataset = datasets(dataset, y, test_size=0.15)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = NetV2(input_features=X_tensor.shape[1])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criteria = nn.BCEWithLogitsLoss()\n",
        "resume = 1\n",
        "v1_path = Path('../Output/NetV1.pth')\n",
        "\n",
        "recover = False\n",
        "\n",
        "if v_path.exists() and recover:\n",
        "    print('Recovering old training process...')\n",
        "    checkpoint = torch.load(v1_path)\n",
        "    resume = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    criteria = checkpoint['criteria']\n",
        "else:\n",
        "    print('Ready for new training process... =)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrjXf8kqPeps",
        "outputId": "69d177fe-e8f7-45a5-a95d-d19368009006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/100 | Train loss: 177.31226 | Train accuracy: 0.51351273 | Test loss: 177.20556 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[2/100 | Train loss: 177.32093 | Train accuracy: 0.51351273 | Test loss: 177.21286 | Test accuracy: 0.51351018]\n",
            "Trigger times: 2/5\n",
            "[3/100 | Train loss: 177.31588 | Train accuracy: 0.51351273 | Test loss: 177.20786 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[4/100 | Train loss: 178.04188 | Train accuracy: 0.48648727 | Test loss: 177.9333 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[5/100 | Train loss: 178.15609 | Train accuracy: 0.51351273 | Test loss: 178.04764 | Test accuracy: 0.51351018]\n",
            "Trigger times: 2/5\n",
            "[6/100 | Train loss: 178.02308 | Train accuracy: 0.48648727 | Test loss: 177.91451 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[7/100 | Train loss: 177.39413 | Train accuracy: 0.51351273 | Test loss: 177.28607 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[8/100 | Train loss: 178.06508 | Train accuracy: 0.48648727 | Test loss: 177.95648 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[9/100 | Train loss: 177.36136 | Train accuracy: 0.51351273 | Test loss: 177.25331 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[10/100 | Train loss: 177.56907 | Train accuracy: 0.48648727 | Test loss: 177.46082 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[11/100 | Train loss: 177.3905 | Train accuracy: 0.51351273 | Test loss: 177.28245 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[12/100 | Train loss: 177.50171 | Train accuracy: 0.51351273 | Test loss: 177.3936 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[13/100 | Train loss: 177.43106 | Train accuracy: 0.48648727 | Test loss: 177.32291 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[14/100 | Train loss: 177.41555 | Train accuracy: 0.48648727 | Test loss: 177.30741 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[15/100 | Train loss: 177.31828 | Train accuracy: 0.51351273 | Test loss: 177.21024 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[16/100 | Train loss: 177.53031 | Train accuracy: 0.51351273 | Test loss: 177.42219 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[17/100 | Train loss: 177.35647 | Train accuracy: 0.51351273 | Test loss: 177.24842 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[18/100 | Train loss: 178.04303 | Train accuracy: 0.48648727 | Test loss: 177.93444 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[19/100 | Train loss: 177.34503 | Train accuracy: 0.51351273 | Test loss: 177.23695 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[20/100 | Train loss: 177.82756 | Train accuracy: 0.48648727 | Test loss: 177.71913 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[21/100 | Train loss: 178.15982 | Train accuracy: 0.51351273 | Test loss: 178.05137 | Test accuracy: 0.51351018]\n",
            "Trigger times: 2/5\n",
            "[22/100 | Train loss: 177.32081 | Train accuracy: 0.51351273 | Test loss: 177.21278 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[23/100 | Train loss: 178.57689 | Train accuracy: 0.48648727 | Test loss: 178.46795 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[24/100 | Train loss: 177.56625 | Train accuracy: 0.48648727 | Test loss: 177.458 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[25/100 | Train loss: 177.78317 | Train accuracy: 0.48648727 | Test loss: 177.67477 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[26/100 | Train loss: 177.59842 | Train accuracy: 0.51351273 | Test loss: 177.49027 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[27/100 | Train loss: 177.44841 | Train accuracy: 0.48648727 | Test loss: 177.34024 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[28/100 | Train loss: 177.4543 | Train accuracy: 0.48648727 | Test loss: 177.34613 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[29/100 | Train loss: 177.34429 | Train accuracy: 0.51351273 | Test loss: 177.23625 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[30/100 | Train loss: 177.48945 | Train accuracy: 0.48648727 | Test loss: 177.38126 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[31/100 | Train loss: 177.31774 | Train accuracy: 0.51351273 | Test loss: 177.20969 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[32/100 | Train loss: 177.47857 | Train accuracy: 0.48648727 | Test loss: 177.37038 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[33/100 | Train loss: 177.71759 | Train accuracy: 0.48648727 | Test loss: 177.60923 | Test accuracy: 0.48648982]\n",
            "Trigger times: 2/5\n",
            "[34/100 | Train loss: 177.85736 | Train accuracy: 0.51351273 | Test loss: 177.74908 | Test accuracy: 0.51351018]\n",
            "Trigger times: 3/5\n",
            "[35/100 | Train loss: 177.31713 | Train accuracy: 0.51351273 | Test loss: 177.20908 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[36/100 | Train loss: 178.60892 | Train accuracy: 0.48648727 | Test loss: 178.49996 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[37/100 | Train loss: 177.83535 | Train accuracy: 0.51351273 | Test loss: 177.72708 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[38/100 | Train loss: 177.53461 | Train accuracy: 0.51351273 | Test loss: 177.42649 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[39/100 | Train loss: 177.32908 | Train accuracy: 0.51351273 | Test loss: 177.22104 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[40/100 | Train loss: 177.31915 | Train accuracy: 0.51351273 | Test loss: 177.2111 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[41/100 | Train loss: 177.34377 | Train accuracy: 0.51351273 | Test loss: 177.23569 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[42/100 | Train loss: 177.33814 | Train accuracy: 0.51351273 | Test loss: 177.23007 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[43/100 | Train loss: 177.40068 | Train accuracy: 0.51351273 | Test loss: 177.29262 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[44/100 | Train loss: 177.82145 | Train accuracy: 0.48648727 | Test loss: 177.71302 | Test accuracy: 0.48648982]\n",
            "Trigger times: 2/5\n",
            "[45/100 | Train loss: 177.31587 | Train accuracy: 0.51351273 | Test loss: 177.20783 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[46/100 | Train loss: 177.40163 | Train accuracy: 0.51351273 | Test loss: 177.2935 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[47/100 | Train loss: 178.51986 | Train accuracy: 0.51351273 | Test loss: 178.41121 | Test accuracy: 0.51351018]\n",
            "Trigger times: 2/5\n",
            "[48/100 | Train loss: 177.43339 | Train accuracy: 0.48648727 | Test loss: 177.32524 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[49/100 | Train loss: 177.96613 | Train accuracy: 0.48648727 | Test loss: 177.8576 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[50/100 | Train loss: 177.56007 | Train accuracy: 0.51351273 | Test loss: 177.45193 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[51/100 | Train loss: 177.80627 | Train accuracy: 0.51351273 | Test loss: 177.69801 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[52/100 | Train loss: 177.34944 | Train accuracy: 0.51351273 | Test loss: 177.24136 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[53/100 | Train loss: 177.31774 | Train accuracy: 0.51351273 | Test loss: 177.2097 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[54/100 | Train loss: 177.31823 | Train accuracy: 0.51351273 | Test loss: 177.21019 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[55/100 | Train loss: 177.36314 | Train accuracy: 0.51351273 | Test loss: 177.25509 | Test accuracy: 0.51351018]\n",
            "Trigger times: 2/5\n",
            "[56/100 | Train loss: 177.3162 | Train accuracy: 0.51351273 | Test loss: 177.20815 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[57/100 | Train loss: 179.57486 | Train accuracy: 0.48648727 | Test loss: 179.46526 | Test accuracy: 0.48648982]\n",
            "Trigger times: 1/5\n",
            "[58/100 | Train loss: 180.00883 | Train accuracy: 0.51351273 | Test loss: 179.89934 | Test accuracy: 0.51351018]\n",
            "Trigger times: 2/5\n",
            "[59/100 | Train loss: 177.35767 | Train accuracy: 0.51351273 | Test loss: 177.24957 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[60/100 | Train loss: 177.62619 | Train accuracy: 0.51351273 | Test loss: 177.51802 | Test accuracy: 0.51351018]\n",
            "Trigger times: 1/5\n",
            "[61/100 | Train loss: 177.5325 | Train accuracy: 0.48648727 | Test loss: 177.42427 | Test accuracy: 0.48648982]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n",
            "[62/100 | Train loss: 177.35255 | Train accuracy: 0.51351273 | Test loss: 177.24446 | Test accuracy: 0.51351018]\n",
            "Trigger times: 0/5\n",
            "New checkpoint...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[102], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m wanna_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wanna_train:\n\u001b[1;32m----> 3\u001b[0m     trained_model, train_stats, test_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_as\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv1_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot training this model anymore...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[100], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(device, model, epochs, optimizer, criteria, train_loader, valid_loader, resume, save_as)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(resume, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     47\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m times, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     50\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     51\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:140\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "wanna_train = True\n",
        "if wanna_train:\n",
        "    trained_model, train_stats, test_stats = train(device, model, epochs, optimizer, criteria, train_loader, test_loader, resume=resume, save_as=v1_path)\n",
        "else:\n",
        "    print('Not training this model anymore...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ey4d7XOPeps"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "v1_path_trained = Path('../Trained/NetV1.pth')\n",
        "if v0_path.exists():\n",
        "    print('Copying last checkpoint of model {0} state to trained folder'.format('NetV1'))\n",
        "    shutil.copy(v1_path, v1_path_trained)\n",
        "else:\n",
        "    print('Model {0} is not created yeat'.format('NetV1'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}